# services/llm_handler.py

import base64
import io
import json
import asyncio
import httpx
from openai import AsyncOpenAI
from openai.types.chat import ChatCompletion
from PIL import Image
import cv2
from typing import List, Dict, Tuple, Any

# --- å°å…¥æˆ‘å€‘å»ºç«‹çš„ prompt è®€å–å·¥å…· ---
from utils.prompt_loader import load_prompt_template

# ä½¿ç”¨ AsyncClient é€²è¡ŒéåŒæ­¥è«‹æ±‚
aclient = httpx.AsyncClient()

# åœ–ç‰‡æœ€å¤§é‚Šé•·é™åˆ¶
MAX_VLM_IMAGE_DIM = 768

def get_openai_client(api_key):
    """æ ¹æ“š API Key åˆå§‹åŒ–ä¸¦è¿”å›ç•°æ­¥çš„ OpenAI å®¢æˆ¶ç«¯ç‰©ä»¶ã€‚"""
    if not api_key:
        return None
    try:
        return AsyncOpenAI(api_key=api_key)
    except Exception as e:
        print(f"åˆå§‹åŒ– OpenAI Client å¤±æ•—: {e}")
        return None

def _image_to_base64(pil_image: Image.Image) -> str:
    """å°‡ PIL.Image ç‰©ä»¶è½‰æ›ç‚º base64 å­—ä¸²ï¼Œä¸¦è‡ªå‹•ç¸®æ”¾ä»¥åŠ é€Ÿ VLM åˆ†æã€‚"""
    width, height = pil_image.size
    
    if max(width, height) > MAX_VLM_IMAGE_DIM:
        if width > height:
            new_width = MAX_VLM_IMAGE_DIM
            new_height = int(height * (new_width / width))
        else:
            new_height = MAX_VLM_IMAGE_DIM
            new_width = int(width * (new_height / height))
        
        pil_image = pil_image.resize((new_width, new_height), Image.Resampling.LANCZOS)

    buffered = io.BytesIO()
    pil_image.save(buffered, format="JPEG", quality=85)
    return base64.b64encode(buffered.getvalue()).decode("utf-8")

async def gpt_image_classify_3cls(face_bgr, client: AsyncOpenAI, model="gpt-4o-mini"):
    """
    (éåŒæ­¥) ä½¿ç”¨ GPT-4o-mini é€²è¡Œä¸‰åˆ†é¡è¡¨æƒ…è¾¨è­˜ã€‚
    """
    if face_bgr is None: return "ç„¡è‡‰", None
    if client is None: return "ï¼ˆæœªè¨­å®š APIï¼‰", None

    pil_img = Image.fromarray(cv2.cvtColor(face_bgr, cv2.COLOR_BGR2RGB))
    b64_img = _image_to_base64(pil_img)
    
    prompt = (
        "è«‹æ ¹æ“šè‡‰éƒ¨è¡¨æƒ…ï¼Œåœ¨ä¸‰é¡ä¸­æ“‡ä¸€è¼¸å‡ºï¼ˆè«‹åªè¼¸å‡ºä¸€å€‹è©ï¼‰ï¼š\n"
        "ã€å–œæ­¡ã€ï¼ˆæ­£å‘/å¾®ç¬‘ï¼‰ã€ã€ä¸­æ€§ã€ã€æˆ–ã€è¨å­ã€ï¼ˆå­æƒ¡/çšºçœ‰ï¼‰ã€‚\n"
        "åªè¼¸å‡ºï¼šå–œæ­¡ / ä¸­æ€§ /è¨å­ã€‚"
    )
    
    try:
        resp = await client.chat.completions.create(
            model=model,
            messages=[{
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64_img}"}},
                ],
            }],
            temperature=0, max_tokens=10
        )
        text = resp.choices[0].message.content.strip()
        usage = resp.usage

        emotion = "ä¸­æ€§"
        if "å–œæ­¡" in text: emotion = "å–œæ­¡"
        if "è¨å­" in text: emotion = "è¨å­"
        
        return emotion, usage

    except Exception as e:
        print(f"è¡¨æƒ…åˆ†é¡ API éŒ¯èª¤: {e}")
        return "API éŒ¯èª¤", None


async def gpt_food_from_menu(plate_bgr, menu_items, client: AsyncOpenAI, model="gpt-4o-mini"):
    """(éåŒæ­¥) æ ¹æ“šæä¾›çš„èœå–®ï¼Œä½¿ç”¨ GPT-4o-mini è¾¨è­˜ç•«é¢ä¸­çš„é¤é»ã€‚"""
    if plate_bgr is None: return {"label": "æœªçŸ¥", "confidence": 0.0, "rationale": "ç„¡ROI"}
    if client is None: return {"label": "ï¼ˆæœªè¨­å®šAPIï¼‰", "confidence": 0.0, "rationale": ""}

    pil_img = Image.fromarray(cv2.cvtColor(plate_bgr, cv2.COLOR_BGR2RGB))
    b64_img = _image_to_base64(pil_img)

    options = ", ".join(menu_items)
    prompt = (
        "è«‹åªæ ¹æ“šæä¾›çš„èœå–®æ¸…å–®åˆ¤æ–·ç•«é¢ä¸­çš„é¤é»å±¬æ–¼å“ªä¸€é …ï¼Œä¸¦ä»¥ JSON æ ¼å¼è¼¸å‡ºï¼š\n"
        '{ "label": "<å¾èœå–®ä¸­æ“‡ä¸€>", "confidence": 0.0~1.0 çš„å°æ•¸, "rationale": "ä¸€å¥ç°¡çŸ­çš„åˆ¤æ–·åŸå› " }\n'
        f"èœå–®æ¸…å–®ï¼š[{options}]\n"
        "å¦‚æœç•«é¢ä¸­çš„é¤é»èˆ‡ä»»ä½•æ¸…å–®é …ç›®éƒ½ä¸å¤ªç›¸ç¬¦ï¼Œè«‹é¸æ“‡æœ€ç›¸è¿‘çš„ä¸€é …ï¼Œä½†çµ¦äºˆè¼ƒä½çš„ä¿¡å¿ƒåº¦ï¼ˆ<=0.4ï¼‰ã€‚\n"
        "è«‹å‹™å¿…åªè¼¸å‡º JSON ç‰©ä»¶ï¼Œä¸è¦åŒ…å«ä»»ä½•å‰å¾Œçš„æ–‡å­—æˆ– markdown æ¨™ç±¤ã€‚"
    )

    try:
        resp = await client.chat.completions.create(
            model=model, response_format={"type": "json_object"},
            messages=[{
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64_img}"}},
                ],
            }],
            temperature=0
        )
        text = resp.choices[0].message.content.strip()
        data = json.loads(text)
        return {
            "label": str(data.get("label", "æœªçŸ¥")),
            "confidence": float(data.get("confidence", 0.0)),
            "rationale": str(data.get("rationale", ""))[:120]
        }
    except Exception as e:
        print(f"é£Ÿç‰©åˆ†é¡ API éŒ¯èª¤: {e}")
        return {"label": "è§£æå¤±æ•—", "confidence": 0.0, "rationale": str(e)[:120]}


async def analyze_plate_vlm(plate_bgr: Any, client: AsyncOpenAI, 
                            food_detections: List[Dict[str, Any]] = None, 
                            model="gpt-4o-mini"):
    """
    (éåŒæ­¥) ä½¿ç”¨ VLM (GPT-4o-mini) åˆ†æé¤ç›¤å‰©é£ŸåŸå› ã€‚
    """
    if plate_bgr is None: return None, None
    if client is None: return None, None

    pil_img = Image.fromarray(cv2.cvtColor(plate_bgr, cv2.COLOR_BGR2RGB))
    b64_img = _image_to_base64(pil_img)

    yolo_info = ""
    if food_detections:
        formatted_dets = [
            f"{det['label']} (ä¿¡å¿ƒåº¦: {det['conf']:.2f})"
            for det in food_detections
        ]
        if formatted_dets:
            yolo_info = "\n[ç³»çµ±æç¤º] YOLO æ¼”ç®—æ³•åœ¨ç•«é¢ä¸­åµæ¸¬åˆ°äº†ï¼š " + ", ".join(formatted_dets)

    system_prompt = (
        "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é¤å»³ç‡Ÿé‹é¡§å•ã€‚è«‹è§€å¯Ÿé€™å¼µé¤ç›¤å›æ”¶çš„ç…§ç‰‡ã€‚"
        "è«‹å…ˆåˆ¤æ–·é¤ç›¤ç‹€æ…‹ï¼Œä¸¦ä¾æ“šæƒ…æ³æ“‡ä¸€å›ç­” (ç¹é«”ä¸­æ–‡ï¼Œ50å­—ä»¥å…§)ï¼š\n\n"
        "æƒ…æ³ Aï¼šå¦‚æœæ˜¯ã€ç©ºç›¤ã€æˆ–ã€åƒå¾—å¾ˆä¹¾æ·¨ã€\n"
        "è«‹å›ç­”ï¼šã€Œé¡§å®¢å°é¤é»æ¥å—åº¦é«˜ï¼Œå®Œé£Ÿç„¡æµªè²»ã€‚ã€é€™é¡æ­£é¢è©•åƒ¹ï¼Œä¸è¦æé€ å‰©é£ŸåŸå› ã€‚\n\n"
        "æƒ…æ³ Bï¼šå¦‚æœæœ‰ã€æ˜é¡¯å‰©é£Ÿã€\n"
        "è«‹å›ç­”ï¼š\n"
        "1. å‰©ä¸‹äº†ä»€éº¼å…·é«”é£Ÿç‰©ï¼Ÿ(ä¾‹å¦‚ï¼šé’æ¤’ã€æ¾±ç²‰ã€è‚‰é¡)\n"
        "2. æ¨æ¸¬å‰©é£ŸåŸå› ï¼Ÿ(ä¾‹å¦‚ï¼šå®Œå…¨æœªå‹•å¯èƒ½æ˜¯ä¸æ„›åƒã€å‰©ä¸€åŠå¯èƒ½æ˜¯ä»½é‡å¤ªå¤§)"
    )
    
    user_prompt = f"è«‹åˆ†æé€™å¼µå‰©é£Ÿç…§ç‰‡ã€‚{yolo_info}"

    try:
        resp = await client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": user_prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64_img}"}},
                    ],
                }
            ],
            max_tokens=150, 
            temperature=0.3 
        )
        content = resp.choices[0].message.content.strip()
        usage = resp.usage
        return content, usage
    except Exception as e:
        print(f"VLM é¤ç›¤åˆ†æéŒ¯èª¤: {e}")
        return f"API éŒ¯èª¤: {str(e)[:50]}", None


# â˜…â˜…â˜… [ä¿®æ­£é‡é»] æ–°å¢ custom_instructions åƒæ•¸ï¼Œä¸¦è¨­ç‚ºé è¨­ None â˜…â˜…â˜…
async def summarize_session(stats: dict, 
                            client: AsyncOpenAI, 
                            store_type: str = "é¤å»³", 
                            tone: str = "å°ˆæ¥­", 
                            tips_style: str = "é è¨­",
                            custom_instructions: str = None,  # <--- æ–°å¢é€™å€‹
                            model="gpt-4o-mini"):
    """
    (éåŒæ­¥) æ ¹æ“šçµ±è¨ˆæ•¸æ“šï¼Œç”Ÿæˆå®¢è£½åŒ–çš„é¡§å®¢é«”é©—æ‘˜è¦å ±å‘Šã€‚
    æ”¯æ´ custom_instructions ä»¥è¦†å¯«é è¨­ Promptã€‚
    """
    if client is None:
        return "ï¼ˆæœªè¨­å®š OPENAI_API_KEYï¼Œç„¡æ³•ç”¢ç”Ÿæ‘˜è¦ï¼‰", None

    try:
        system_template = load_prompt_template('summarize_session', 'system')
        # å¦‚æœæ²’æœ‰è‡ªè¨‚æŒ‡ä»¤ï¼Œæ‰å»è®€å–é è¨­çš„ user template
        if not custom_instructions:
            user_template = load_prompt_template('summarize_session', 'user')
    except FileNotFoundError as e:
        error_msg = f"æ‰¾ä¸åˆ° Prompt æ¨¡æ¿æª”æ¡ˆï¼š{e}ã€‚è«‹ç¢ºèª 'prompts/summarize_session/' è³‡æ–™å¤¾åŠå…§éƒ¨çš„ .txt æª”æ¡ˆæ˜¯å¦å­˜åœ¨ã€‚"
        print(error_msg)
        return error_msg, None

    # 1. è™•ç† System Prompt
    system_prompt = system_template.replace('{store_type}', str(store_type)) \
                                   .replace('{tone}', str(tone)) \
                                   .replace('{tips_style}', str(tips_style))

    # 2. è™•ç† User Prompt (åˆ¤æ–·æ˜¯å¦ä½¿ç”¨è‡ªè¨‚æŒ‡ä»¤)
    if custom_instructions:
        # â˜… å¦‚æœæœ‰è‡ªè¨‚æŒ‡ä»¤ï¼Œç›´æ¥ä½¿ç”¨å®ƒ (Dashboard æ¨¡å¼)
        user_prompt = custom_instructions
    else:
        # â˜… å¦å‰‡ä½¿ç”¨é è¨­æ¨¡æ¿ä¸¦å¡«å…¥æ•¸æ“š (Video/Live æ¨¡å¼)
        json_str = json.dumps(stats, indent=2, ensure_ascii=False)
        user_prompt = user_template.replace('{stats_json}', json_str)
    
    try:
        r: ChatCompletion = await client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.7, max_tokens=800,
        )
        summary_text = r.choices[0].message.content
        usage_data = r.usage
        return summary_text, usage_data
        
    except Exception as e:
        error_msg = f"ç”Ÿæˆæ‘˜è¦æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"
        print(f"æ‘˜è¦ç”Ÿæˆ API éŒ¯èª¤: {e}")
        return error_msg, None
    
async def identify_food_item(plate_bgr, menu_items: list, client: AsyncOpenAI, model="gpt-4o"):
    """
    é‡å°å¼·çƒˆæƒ…ç·’è§¸ç™¼çš„å¿«ç…§ï¼Œé€²è¡Œé«˜ç²¾æº–åº¦çš„é£Ÿç‰©è¾¨è­˜ã€‚
    
    Args:
        plate_bgr: OpenCV æ ¼å¼çš„å½±åƒ (BGR)
        menu_items: å€™é¸èœå–®åˆ—è¡¨ (ä¾‹å¦‚ ["æ¼¢å ¡", "é›å¡Š", "è–¯æ¢"])
        client: OpenAI Client
        model: å»ºè­°ä½¿ç”¨ gpt-4o ä»¥ç²å¾—æœ€ä½³è¦–è¦ºè¾¨è­˜èƒ½åŠ›
        
    Returns:
        str: è¾¨è­˜å‡ºçš„é£Ÿç‰©åç¨± (ä¾‹å¦‚ "æ¼¢å ¡")ï¼Œè‹¥å¤±æ•—å‰‡å›å‚³ "Unknown"
    """
    if plate_bgr is None: return "Unknown"
    if client is None: return "No_API_Key"

    # 1. åœ–ç‰‡è½‰ Base64
    pil_img = Image.fromarray(cv2.cvtColor(plate_bgr, cv2.COLOR_BGR2RGB))
    b64_img = _image_to_base64(pil_img)

    # 2. æº–å‚™é¸å–®å­—ä¸² (ç¢ºä¿æœ‰ Other é¸é …)
    safe_menu = menu_items.copy()
    if "å…¶ä»–" not in safe_menu and "Other" not in safe_menu:
        safe_menu.append("Other")
    
    options_str = ", ".join(safe_menu)
    
    # 3. å»ºæ§‹ Prompt (è¦æ±‚ç²¾ç°¡å›ç­”)
    prompt = (
        f"è«‹è§€å¯Ÿé€™å¼µé¤ç›¤ç…§ç‰‡ï¼Œä¸¦å¾ä»¥ä¸‹æ¸…å–®ä¸­é¸å‡ºæœ€ç¬¦åˆçš„é£Ÿç‰©åç¨±ï¼š\n"
        f"æ¸…å–®ï¼š[{options_str}]\n"
        "è«‹ç›´æ¥å›å‚³è©²åç¨±ï¼Œä¸è¦åŠ ä»»ä½•æ¨™é»ç¬¦è™Ÿæˆ–é¡å¤–æ–‡å­—(ä¾‹å¦‚ä¸è¦å›å‚³ 'æ˜¯æ¼¢å ¡'ï¼Œåªè¦å›å‚³ 'æ¼¢å ¡')ã€‚\n"
        "å¦‚æœå®Œå…¨çœ‹ä¸å‡ºä¾†ã€ç©ºç›¤æˆ–ä¸åœ¨æ¸…å–®ä¸­ï¼Œè«‹å›å‚³ 'Other'ã€‚"
    )

    try:
        resp = await client.chat.completions.create(
            model=model,
            messages=[{
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64_img}"}},
                ],
            }],
            temperature=0.1, # ä½éš¨æ©Ÿæ€§ï¼Œç¢ºä¿ç­”æ¡ˆç©©å®š
            max_tokens=20
        )
        
        # 4. å–å¾—çµæœ
        text = resp.choices[0].message.content.strip()
        
        # ç°¡å–®é˜²å‘†ï¼šç¢ºä¿å›å‚³çš„æ–‡å­—çœŸçš„åœ¨æˆ‘å€‘çš„æ¸…å–®è£¡
        # (æœ‰æ™‚å€™ LLM æœƒå›å‚³ "æ‡‰è©²æ˜¯æ¼¢å ¡"ï¼Œæˆ‘å€‘åªè¦ "æ¼¢å ¡")
        for item in safe_menu:
            if item in text:
                return item
                
        return text # å¦‚æœéƒ½æ²’å°åˆ°ï¼Œå°±å›å‚³åŸå§‹ç­”æ¡ˆ (é€šå¸¸æ˜¯ Other)

    except Exception as e:
        print(f"Food ID Error: {e}")
        return "Error"
    
async def generate_menu_report(food_stats: dict, client: AsyncOpenAI, model="gpt-4o-mini"):
    """
    (éåŒæ­¥) å°ˆé–€é‡å°ã€Œèœè‰²ã€ç”Ÿæˆç ”ç™¼èˆ‡èª¿æ•´å»ºè­°å ±å‘Šã€‚
    """
    if not client: return "ï¼ˆæœªè¨­å®š API Keyï¼‰", None

    # å°‡çµ±è¨ˆæ•¸æ“šè½‰ç‚º JSON å­—ä¸²
    stats_str = json.dumps(food_stats, ensure_ascii=False, indent=2)

    system_prompt = (
        "ä½ æ˜¯ä¸€ä½æ“æœ‰ 20 å¹´ç¶“é©—çš„ã€é¤é£²èœè‰²ç ”ç™¼é¡§å•ã€ã€‚ä½ çš„å·¥ä½œæ˜¯æ ¹æ“šé¡§å®¢å°ç‰¹å®šèœè‰²çš„æƒ…ç·’åæ‡‰æ•¸æ“šï¼Œ"
        "ç‚ºå…§å ´ä¸»å»šæä¾›å…·é«”çš„èœå–®èª¿æ•´å»ºè­°ã€‚\n\n"
        "ã€æ•¸æ“šèªªæ˜ã€‘\n"
        "è¼¸å…¥çš„ JSON æ ¼å¼ç‚ºï¼š{'èœå': {'é–‹å¿ƒ': æ¬¡æ•¸, 'å«Œæ£„': æ¬¡æ•¸, ...}}\n\n"
        "ã€å ±å‘Šçµæ§‹è¦æ±‚ã€‘\n"
        "1. ğŸ† **æ˜æ˜Ÿèœè‰² (Star Dishes)**ï¼šæ­£é¢æƒ…ç·’ä½”æ¯”æœ€é«˜çš„èœã€‚åˆ†æå…¶æˆåŠŸå¯èƒ½çš„å› ç´ ï¼ˆå£å‘³ã€è³£ç›¸ï¼‰ã€‚\n"
        "2. ğŸ’£ **å•é¡Œèœè‰² (Problem Dishes)**ï¼šè² é¢æƒ…ç·’ï¼ˆå«Œæ£„/å¤±æœ›/ä¸æ»¿ï¼‰è¼ƒé«˜çš„èœã€‚è«‹å¤§è†½æ¨æ¸¬å¯èƒ½åŸå› ï¼ˆå¦‚ï¼šèª¿å‘³éé‡ã€å†·æ‰ã€é£Ÿææ­é…æ€ªç•°ï¼‰ã€‚\n"
        "3. ğŸ”ª **ä¸»å»šè¡Œå‹•å»ºè­° (Action Plan)**ï¼šé‡å°å•é¡Œèœè‰²ï¼Œæå‡º 2-3 å€‹å…·é«”çš„æ”¹è‰¯æ–¹å‘ï¼ˆä¾‹å¦‚ï¼šèª¿æ•´é†¬æ±æ¯”ä¾‹ã€æ›´æ›ç››ç›¤æ–¹å¼ï¼‰ã€‚\n"
        "è«‹ç”¨å°ˆæ¥­ã€ç›´ç™½ä¸”å»ºè¨­æ€§çš„èªæ°£æ’°å¯«ï¼Œä¸è¦è¬›ç©ºè©±ã€‚"
    )

    user_prompt = f"è«‹åˆ†ææœ¬é€±çš„èœè‰²æƒ…ç·’æ•¸æ“šï¼š\n{stats_str}"

    try:
        resp = await client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7
        )
        return resp.choices[0].message.content, resp.usage
    except Exception as e:
        return f"ç”Ÿæˆèœè‰²å ±å‘Šå¤±æ•—: {e}", None