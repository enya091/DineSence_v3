# services/vision_analysis.py
"""
æ‰€æœ‰é›»è…¦è¦–è¦ºç›¸é—œæ¼”ç®—æ³•é›†ä¸­æ–¼æ­¤ï¼š
- é¤ç›¤æ®˜ç•™åµæ¸¬
- é ­éƒ¨å‹•ä½œåµæ¸¬ï¼ˆé»é ­ / æ–é ­ï¼‰
- è‡‰éƒ¨æ“·å–
- YOLO é£Ÿç‰©åµæ¸¬
"""

import cv2
import numpy as np
import time
from collections import deque
import mediapipe as mp
from ultralytics import YOLO

import config as _cfg


# --------------------------------------------------
#  è®€å– config åƒæ•¸ (é€™è£¡æˆ‘ç›´æ¥æŠŠé è¨­å€¼æ”¹æˆå¯¬é¬†ç‰ˆï¼Œç¢ºä¿ä½ å°±ç®— config æ²’æ”¹ä¹Ÿèƒ½å‹•)
# --------------------------------------------------

YOLO_MODEL_PATH  = getattr(_cfg, "YOLO_MODEL_PATH", "yolov8n.pt")
FOODISH_CLASSES  = getattr(_cfg, "FOODISH_CLASSES", set())

# Head Gesture åƒæ•¸ (ä½¿ç”¨å¯¬é¬†ç‰ˆ Defaults)
GESTURE_BUFFER_LEN = getattr(_cfg, "GESTURE_BUFFER_LEN", 20)
GESTURE_COOLDOWN   = getattr(_cfg, "GESTURE_COOLDOWN_SECONDS", 0.8)
GESTURE_MIN_OFFSET = getattr(_cfg, "GESTURE_MIN_OFFSET", 0.002)

# â˜…â˜…â˜… é€™è£¡ç›´æ¥æ”¹å¯¬é¬†ï¼Œä¸ç”¨æ€• config æ²’è¨­å° â˜…â˜…â˜…
NOD_AMP_THRESH     = getattr(_cfg, "NOD_AMP_THRESH", 0.008)       # å¾ˆå®¹æ˜“è§¸ç™¼
SHAKE_AMP_THRESH   = getattr(_cfg, "SHAKE_AMP_THRESH", 0.010)
MAX_SECONDARY_AMP  = getattr(_cfg, "MAX_SECONDARY_AMP", 0.020)    # å®¹è¨±é ­æ™ƒå‹•
MIN_OSC_COUNT      = getattr(_cfg, "MIN_OSC_COUNT", 2)            # ä¾†å›å…©æ¬¡å°±ç®—

MIN_FACE_CONF = getattr(_cfg, "MIN_FACE_CONF", 0.6)


# --------------------------------------------------
#  æ¨¡å‹åˆå§‹åŒ–
# --------------------------------------------------

try:
    _yolo_food = YOLO(YOLO_MODEL_PATH)
    _yolo_ok = True
except Exception as e:
    print(f"[YOLO è¼‰å…¥å¤±æ•—] {e}")
    _yolo_food = None
    _yolo_ok = False

mp_pose = mp.solutions.pose
mp_face = mp.solutions.face_detection


def get_pose_detector():
    return mp_pose.Pose(
        model_complexity=0,
        enable_segmentation=False,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5,
    )


def get_face_detector():
    return mp_face.FaceDetection(
        model_selection=0,
        min_detection_confidence=0.5
    )

# --------------------------------------------------
#  (A) é¤ç›¤æ®˜ç•™åµæ¸¬
# --------------------------------------------------

def estimate_plate_leftover(bgr_frame):
    gray = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (9, 9), 2)

    circles = cv2.HoughCircles(
        gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=120,
        param1=100, param2=30, minRadius=60, maxRadius=0
    )

    if circles is None:
        return "æœªåµæ¸¬åˆ°é¤ç›¤", None, None

    circles = np.round(circles[0, :]).astype("int")
    x, y, r = max(circles, key=lambda c: c[2])

    h, w = bgr_frame.shape[:2]
    if x - r < 0 or y - r < 0 or x + r >= w or y + r >= h:
        return "é¤ç›¤ä¸å®Œæ•´", None, (x, y, r)

    roi = bgr_frame[y-r:y+r, x-r:x+r].copy()

    mask = np.zeros((2*r, 2*r), dtype=np.uint8)
    cv2.circle(mask, (r, r), r - 2, 255, -1)

    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    H, S, V = cv2.split(hsv)

    white_mask = (S < 50) & (V > 200)
    food_mask = (~white_mask) & (mask > 0)

    total = np.count_nonzero(mask)
    food_pixels = np.count_nonzero(food_mask)

    if total == 0:
        return "é¤ç›¤å€åŸŸç„¡æ•ˆ", None, (x, y, r)

    ratio = food_pixels / total
    label = "å‰©é¤˜50%ä»¥ä¸Š" if ratio >= 0.5 else "ç„¡å‰©é¤˜"

    return label, float(ratio), (x, y, r)


# --------------------------------------------------
#  (B) é ­éƒ¨å‹•ä½œåµæ¸¬ (HeadGestureDetector)
# --------------------------------------------------

class HeadGestureDetector:
    """
    åš´æ ¼ç‰ˆé ­éƒ¨å‹•ä½œåµæ¸¬ï¼š
    - åŒæ™‚çœ‹ X / Y ç›¸å°ä½ç§»çš„æ³¢å½¢
    - é»é ­ï¼šY æŒ¯å¹…å¤ å¤§ï¼Œè€Œä¸” X å¹¾ä¹æ²’å‹•
    - æ–é ­ï¼šX æŒ¯å¹…å¤ å¤§ï¼Œè€Œä¸” Y å¹¾ä¹æ²’å‹•
    """

    def __init__(
        self,
        buf_len=GESTURE_BUFFER_LEN,
        nod_amp_thresh=NOD_AMP_THRESH,
        shake_amp_thresh=SHAKE_AMP_THRESH,
        max_secondary_amp=MAX_SECONDARY_AMP,
        min_osc=MIN_OSC_COUNT,
        cooldown=GESTURE_COOLDOWN,
        min_offset=GESTURE_MIN_OFFSET,
    ):
        self.buf_len = buf_len
        self.nod_amp_thresh = nod_amp_thresh
        self.shake_amp_thresh = shake_amp_thresh
        self.max_secondary_amp = max_secondary_amp
        self.min_osc = min_osc
        self.cooldown = cooldown
        self.min_offset = min_offset

        self.x_hist = deque(maxlen=buf_len)
        self.y_hist = deque(maxlen=buf_len)
        self.last_event_ts = 0.0

    def reset(self):
        self.x_hist.clear()
        self.y_hist.clear()
        self.last_event_ts = 0.0

    def _osc_features(self, arr: np.ndarray):
        if arr.size < 3:
            return 0.0, 0
        amp = float(arr.max() - arr.min())
        diff1 = np.diff(arr)
        sign_changes = int(np.sum(np.diff(np.sign(diff1)) != 0))
        return amp, sign_changes

    def update_and_classify(self, dx, dy):
        """
        ã€æ¯”ä¾‹åˆ¤å®šç‰ˆã€‘
        ä¸å†ä½¿ç”¨å›ºå®šçš„ MAX_SECONDARY_AMP å¡æ­»ï¼Œ
        è€Œæ˜¯æ¯”è¼ƒ X èˆ‡ Y çš„ç›¸å°å¤§å°ã€‚
        """
        # 1. å»æŠ–å‹•
        if abs(dx) < self.min_offset: dx = 0.0
        if abs(dy) < self.min_offset: dy = 0.0

        self.x_hist.append(dx)
        self.y_hist.append(dy)

        if len(self.x_hist) < self.x_hist.maxlen:
            return None

        now = time.time()
        if (now - self.last_event_ts) < self.cooldown:
            return None

        # 3. è¨Šè™Ÿè™•ç†
        arr_x = np.array(self.x_hist, dtype=np.float32)
        arr_y = np.array(self.y_hist, dtype=np.float32)

        arr_x = arr_x - arr_x.mean()
        arr_y = arr_y - arr_y.mean()

        arr_x = cv2.GaussianBlur(arr_x.reshape(-1, 1), (5, 1), 0).flatten()
        arr_y = cv2.GaussianBlur(arr_y.reshape(-1, 1), (5, 1), 0).flatten()

        # 4. æå–ç‰¹å¾µ
        amp_x, osc_x = self._osc_features(arr_x)
        amp_y, osc_y = self._osc_features(arr_y)

        event = None
        
        # â˜…â˜…â˜… é€™è£¡æ”¹æˆäº†æ¯”ä¾‹åˆ¤å®š â˜…â˜…â˜…
        
        # å®šç¾©ä¸€å€‹æ¯”ç‡ï¼Œä¾‹å¦‚ä¸»è»¸å¿…é ˆæ˜¯å‰¯è»¸çš„ 1.5 å€å¤§
        RATIO = 1.2 

        # --- åˆ¤å®šé»é ­ (Y ç‚ºä¸») ---
        # æ¢ä»¶1: Y æŒ¯å¹…å¤ å¤§
        # æ¢ä»¶2: Y æŒ¯å¹… æ˜é¡¯å¤§æ–¼ X æŒ¯å¹… (ä¸å†ç”¨å›ºå®šå€¼å¡)
        # æ¢ä»¶3: æœ‰ä¾†å›å‹•ä½œ
        if (amp_y >= self.nod_amp_thresh and 
            amp_y > (amp_x * RATIO) and 
            osc_y >= self.min_osc):
            event = "nod"

        # --- åˆ¤å®šæ–é ­ (X ç‚ºä¸») ---
        elif (amp_x >= self.shake_amp_thresh and 
              amp_x > (amp_y * RATIO) and 
              osc_x >= self.min_osc):
            event = "shake"

        # Debug è¼¸å‡º
        if amp_y > 0.01 or amp_x > 0.01:
            print(f"[Debug] åˆ¤å®š:{event} | Y:{amp_y:.4f} vs X:{amp_x:.4f} | (æ¯”ç‡æª¢æŸ¥: {'Pass' if event else 'Fail'})")

        if event:
            self.last_event_ts = now
            print(f"ğŸš€ è§¸ç™¼å‹•ä½œ: {event} !!!")
        
        return event


# --------------------------------------------------
#  (C) è‡‰éƒ¨æ“·å–
# --------------------------------------------------

def crop_face_with_mediapipe(bgr_frame, detector, min_conf=0.6):
    rgb = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)
    res = detector.process(rgb)

    if not res.detections:
        return None

    det = res.detections[0]
    if det.score[0] < min_conf:
        return None

    h, w = bgr_frame.shape[:2]
    bbox = det.location_data.relative_bounding_box

    x1 = max(0, int(bbox.xmin * w))
    y1 = max(0, int(bbox.ymin * h))
    x2 = min(w, int((bbox.xmin + bbox.width) * w))
    y2 = min(h, int((bbox.ymin + bbox.height) * h))

    if x2 <= x1 or y2 <= y1:
        return None

    return bgr_frame[y1:y2, x1:x2]


# --------------------------------------------------
#  (D) YOLO é£Ÿç‰©åµæ¸¬
# --------------------------------------------------

def detect_food_regions_yolo(bgr, conf=0.3, min_area_ratio=0.01):
    if not _yolo_ok:
        return []

    res = _yolo_food(bgr, conf=conf, iou=0.45, verbose=False)[0]
    h, w = bgr.shape[:2]

    out = []
    for b in res.boxes:
        name = res.names.get(int(b.cls.item()), "")
        if name not in FOODISH_CLASSES:
            continue

        x1, y1, x2, y2 = map(int, b.xyxy[0].tolist())
        area = (x2 - x1) * (y2 - y1)
        if area / (w * h) < min_area_ratio:
            continue

        out.append({
            "xyxy": (x1, y1, x2, y2),
            "label": name,
            "conf": float(b.conf.item()),
        })

    return out


def has_big_cup(bgr, min_area_ratio=0.04):
    if not _yolo_ok:
        return False

    res = _yolo_food(bgr, conf=0.3, iou=0.45, verbose=False)[0]
    h, w = bgr.shape[:2]

    for b in res.boxes:
        name = res.names.get(int(b.cls.item()), "")
        if name in ["cup", "wine glass", "bottle"]:
            x1, y1, x2, y2 = map(int, b.xyxy[0].tolist())
            if ((x2 - x1) * (y2 - y1)) / (w * h) >= min_area_ratio:
                return True

    return False