# ui/dashboard_view.py

import streamlit as st
import pandas as pd
import json
import asyncio
import datetime
import ast
import os
from collections import Counter
from services import llm_handler as llm
from services.database import DatabaseManager 
import plotly.express as px
from io import BytesIO
from docx import Document


EVIDENCE_DIR = "session_evidence"


def _create_docx(text_content):
    """
    å°‡æ–‡å­—å…§å®¹è½‰æ›ç‚º Word æ–‡ä»¶ (BytesIO)
    """
    doc = Document()
    doc.add_heading('DineSence AI Report', 0)
    
    # ç°¡å–®è™•ç†ï¼šæŒ‰è¡Œå¯«å…¥ï¼Œä¿ç•™æ®µè½æ„Ÿ
    for line in text_content.split('\n'):
        doc.add_paragraph(line)
        
    bio = BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio

# è¼”åŠ©å‡½å¼ï¼šåœ–ç‰‡ Grid
def _render_evidence_grid(db_manager, session_id, event_type):
    """
    è² è²¬è®€å–ä¸¦é¡¯ç¤ºåœ–ç‰‡ Gridï¼Œä¸åŒ…å«å¤–å±¤çš„ Expanderã€‚
    """
    evidence_df = db_manager.get_event_evidence(session_id, event_type)
    
    if evidence_df.empty:
        st.info("NO EVIDENCE FOUND.", icon="â„¹ï¸")
        return

    # é™åˆ¶é¡¯ç¤ºæ•¸é‡ï¼Œé¿å…ä¸€æ¬¡è¼‰å…¥å¤ªå¤šç•¶æ©Ÿ
    cols = st.columns(4) 
    
    for i, row in evidence_df.iterrows():
        filename = os.path.basename(row['local_path'])
        path = os.path.join(EVIDENCE_DIR, filename)
        
        evidence_id = row['id']
        is_correct = row['human_corrected']
        
        # æ±ºå®šåœ–ç‰‡æ”¾åœ¨å“ªä¸€æ¬„
        col = cols[i % 4]
        
        if os.path.exists(path):
            with col:
                st.image(path, use_container_width=True)
                
                checkbox_key = f"img_feedback_{evidence_id}_{session_id}"
                
                def update_feedback(eid=evidence_id, key=checkbox_key):
                    new_state = st.session_state[key]
                    db_manager.update_evidence_feedback(eid, new_state)
                    if new_state:
                        st.toast(f"âœ… ID {eid} CONFIRMED", icon="ğŸ‘")

                st.checkbox(
                    f"#{evidence_id} CONFIRM", 
                    value=(is_correct == 1), 
                    key=checkbox_key,
                    on_change=update_feedback
                )
        else:
            with col:
                st.warning(f"MISSING {evidence_id}")

def _render_global_insights(client, db_manager, df_sessions, t):
    """
    [NEW] ç¸½é«”æ•¸æ“šæ´å¯Ÿï¼šè·¨ Session çš„èœè‰²æƒ…ç·’çµ±è¨ˆèˆ‡ LLM å ±å‘Š
    """
    st.info("æ­¤é é¢çµ±è¨ˆç¯„åœç‚ºä¸Šæ–¹ã€Œç¯©é¸å™¨ã€æ‰€é¸å®šä¹‹æ™‚é–“æ®µå…§çš„æ•¸æ“šã€‚")

    if df_sessions.empty:
        st.warning("âš ï¸ ç›®å‰é¸å®šçš„æ™‚é–“ç¯„åœå…§ç„¡ Session è³‡æ–™ã€‚")
        return

    # 1. è·¨ Session è³‡æ–™èšåˆ (Data Aggregation)
    all_food_data = []
    
    # éæ­·ç¯©é¸å‡ºçš„æ‰€æœ‰ Session
    for _, session_row in df_sessions.iterrows():
        sid = session_row['session_id_raw']
        
        # æ’ˆå–è©² Session çš„é¤é»è­‰æ“š
        df_evidence = db_manager.get_event_evidence(sid, "strong_emotion_plate")
        
        if df_evidence.empty: continue
            
        for _, row in df_evidence.iterrows():
            # æ’é™¤äººå·¥å¦æ±ºçš„è³‡æ–™
            if row['human_corrected'] == 0: continue
                
            food_name = row['food_label'] if row['food_label'] else "Unknown"
            
            # è§£ææƒ…ç·’ (å¾æª”å)
            # æª”åæ ¼å¼: æ™‚é–“_æƒ…ç·’-åˆ†_...
            try:
                fname = os.path.basename(row['local_path'])
                parts = fname.split('_')
                emotion_tag = parts[2].split('-')[0] # å–å‡º "é–‹å¿ƒ"
                
                all_food_data.append({
                    "session_id": sid,
                    "evidence_id": row['id'],
                    "food": food_name,
                    "emotion": emotion_tag,
                    "path": row['local_path'],
                    "timestamp": row['session_timestamp'] # é€™è£¡å¯èƒ½æ˜¯ session_idï¼Œéœ€æ³¨æ„é¡¯ç¤ºæ ¼å¼
                })
            except:
                continue

    if not all_food_data:
        st.warning("âš ï¸ åœ¨æ­¤æ™‚é–“ç¯„åœå…§ï¼Œå°šæœªåµæ¸¬åˆ°ä»»ä½•æœ‰æ•ˆçš„é¤é»æƒ…ç·’æ•¸æ“šã€‚")
        return

    df_analysis = pd.DataFrame(all_food_data)

    # 2. çµ±è¨ˆæ•¸æ“šæº–å‚™ (çµ¦ LLM ç”¨)
    # æ ¼å¼: {'æ¼¢å ¡': {'é–‹å¿ƒ': 5, 'å«Œæ£„': 1}, 'è–¯æ¢': ...}
    food_stats = {}
    for food in df_analysis['food'].unique():
        sub_df = df_analysis[df_analysis['food'] == food]
        counts = sub_df['emotion'].value_counts().to_dict()
        food_stats[food] = counts

    # ==========================================
    # å€å¡Š A: LLM ç¸½é«”æ´å¯Ÿå ±å‘Š
    # ==========================================
    with st.container(border=True):
        st.subheader("ğŸ¤– AI ç‡Ÿé‹æ´å¯Ÿå ±å‘Š")
        st.markdown("è®“ AI ç‚ºæ‚¨åˆ†ææœ¬æ™‚æ®µå…§ï¼Œå„é …é¤é»çš„é¡§å®¢æƒ…ç·’è¡¨ç¾ã€‚")
        
        if st.button(t("btn_gen_insight_report"), type="primary", use_container_width=True):
            if not client:
                st.error("æœªè¨­å®š OpenAI API Key")
            else:
                with st.spinner("AI æ­£åœ¨åˆ†æå¤§æ•¸æ“š..."):
                    # çµ„å»º Prompt
                    stats_str = json.dumps(food_stats, ensure_ascii=False, indent=2)
                    system_prompt = (
                        "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é¤å»³æ•¸æ“šåˆ†æå¸«ã€‚ä½¿ç”¨è€…æœƒæä¾›ä¸€ä»½ JSON æ•¸æ“šï¼Œ"
                        "å…§å®¹æ˜¯ä¸åŒèœè‰²å°æ‡‰çš„é¡§å®¢æƒ…ç·’çµ±è¨ˆ (ä¾‹å¦‚: æ¼¢å ¡ -> é–‹å¿ƒ:5, å«Œæ£„:2)ã€‚\n"
                        "è«‹æ ¹æ“šæ•¸æ“šç”Ÿæˆä¸€ä»½ç¹é«”ä¸­æ–‡å ±å‘Šï¼ŒåŒ…å«ï¼š\n"
                        "1. ğŸ† **æ˜æ˜Ÿèœè‰²**ï¼šå“ªé“èœçš„æ­£é¢æƒ…ç·’(é–‹å¿ƒ/é©šè‰·)æ¯”ä¾‹æœ€é«˜ï¼Ÿ\n"
                        "2. âš ï¸ **æ”¹é€²å»ºè­°**ï¼šå“ªé“èœå‡ºç¾äº†è² é¢æƒ…ç·’(å«Œæ£„/å¤±æœ›/ä¸æ»¿)ï¼Ÿå¯èƒ½åŸå› ï¼Ÿ\n"
                        "3. ğŸ’¡ **ç¸½çµæ´å¯Ÿ**ï¼šæ•´é«”èœå–®çš„è¡¨ç¾è©•åƒ¹ã€‚\n"
                        "è«‹ç”¨å°ˆæ¥­ã€ç°¡æ½”çš„æ¢åˆ—å¼èªæ°£å›ç­”ã€‚"
                    )
                    user_prompt = f"è«‹åˆ†æä»¥ä¸‹é¤é»æƒ…ç·’æ•¸æ“šï¼š\n{stats_str}"

                    async def run_gpt():
                        try:
                            resp = await client.chat.completions.create(
                                model="gpt-4o",
                                messages=[
                                    {"role": "system", "content": system_prompt},
                                    {"role": "user", "content": user_prompt}
                                ],
                                temperature=0.7
                            )
                            return resp.choices[0].message.content
                        except Exception as e:
                            return f"Error: {e}"
                            
                    report_text = asyncio.run(run_gpt())
                    st.markdown("---")
                    st.markdown(report_text)

    st.divider()

    # ==========================================
    # å€å¡Š B: å–®å“é …è©³ç´°åˆ†æ
    # ==========================================
    c1, c2 = st.columns([1, 2])
    
    with c1:
        st.markdown("### ğŸ” èœè‰²ç´°ç¯€æŸ¥è©¢")
        food_list = sorted(list(food_stats.keys()))
        selected_food = st.selectbox("é¸æ“‡è¦é‘½ç ”çš„èœè‰²", food_list)
        
        # é¡¯ç¤ºè©²èœè‰²çš„åŸºæœ¬æ•¸æ“š
        if selected_food:
            stats = food_stats[selected_food]
            total = sum(stats.values())
            st.caption(f"å…±è’é›†åˆ° {total} ç­†åæ‡‰")
            st.json(stats)

    with c2:
        if selected_food:
            # ç•«åœ–
            df_target = df_analysis[df_analysis['food'] == selected_food]
            emo_counts = df_target['emotion'].value_counts().reset_index()
            emo_counts.columns = ['Emotion', 'Count']
            
            fig = px.bar(
                emo_counts, x='Emotion', y='Count',
                title=f"ã€Œ{selected_food}ã€æƒ…ç·’åˆ†ä½ˆåœ–",
                color='Emotion', text_auto=True,
                color_discrete_sequence=px.colors.qualitative.Pastel
            )
            st.plotly_chart(fig, use_container_width=True)

    # ==========================================
    # å€å¡Š C: è­‰æ“šé©—è­‰èˆ‡ä¿®æ­£
    # ==========================================
    st.subheader(f"âœ… è³‡æ–™é©—è­‰ ({selected_food})")
    
    target_records = df_analysis[df_analysis['food'] == selected_food]
    
    # Grid é¡¯ç¤º
    cols = st.columns(4)
    for i, row in target_records.iterrows():
        col = cols[i % 4]
        with col:
            with st.container(border=True):
                # é¡¯ç¤ºåœ–ç‰‡
                if os.path.exists(row['path']):
                    st.image(row['path'], use_container_width=True)
                else:
                    st.warning("å½±åƒéºå¤±")
                
                # æƒ…ç·’æ¨™ç±¤
                st.markdown(f"**{row['emotion']}**")
                
                # å‹¾é¸æ¡†
                chk_key = f"g_chk_{row['evidence_id']}"
                
                def update_cb(eid=row['evidence_id'], k=chk_key):
                    val = st.session_state[k]
                    db_manager.update_evidence_feedback(eid, val)
                    if not val: st.toast(f"å·²å¾çµ±è¨ˆä¸­ç§»é™¤ (ID: {eid})")

                st.checkbox("ç¢ºèªç„¡èª¤", value=True, key=chk_key, on_change=update_cb)

def _render_comparison_gallery(db_manager, session_id):
    """
    [NEW] å¼·çƒˆæƒ…ç·’äº¤å‰æ¯”å°ç•«å»Š
    é‚è¼¯ï¼šæ‰¾å‡ºåŒä¸€æ™‚é–“é»çš„ Face èˆ‡ Plate ç…§ç‰‡ï¼Œä¸¦æ’é¡¯ç¤ºã€‚
    """
    # 1. æ’ˆå‡ºè©² Session æ‰€æœ‰å¼·çƒˆæƒ…ç·’ç›¸é—œçš„è­‰æ“š
    df_face = db_manager.get_event_evidence(session_id, "strong_emotion_face")
    df_plate = db_manager.get_event_evidence(session_id, "strong_emotion_plate")
    
    if df_face.empty and df_plate.empty:
        st.info("å°šæœªåµæ¸¬åˆ°å¼·çƒˆæƒ…ç·’äº‹ä»¶ (Confidence > 40%)")
        return

    # 2. é€²è¡Œé…å° (Pairing)
    # æˆ‘å€‘åˆ©ç”¨æª”åä¸­çš„æ™‚é–“æˆ³è¨˜ (ä¾‹å¦‚ "11æœˆ30æ—¥_12é»01åˆ†05ç§’") ä¾†é…å°
    pairs = {} 
    
    # è™•ç†è‡‰éƒ¨ç…§ç‰‡
    for _, row in df_face.iterrows():
        path = row['local_path']
        filename = os.path.basename(path)
        
        # ä¿®æ­£å¾Œçš„è§£æé‚è¼¯
        parts = filename.split('_')
        # å–å‰å…©æ®µç•¶ä½œå”¯ä¸€çš„æ™‚é–“ Key (æœˆæ—¥_æ™‚åˆ†ç§’)
        key = f"{parts[0]}_{parts[1]}"
        
        # å–å¾—ä¸»è¦æƒ…ç·’åç¨± (ç§»é™¤åˆ†æ•¸)
        raw_emo = parts[2] # "é–‹å¿ƒ-98"
        emo_label = raw_emo.split('-')[0] # "é–‹å¿ƒ"

        if key not in pairs: pairs[key] = {}
        pairs[key]['face'] = path
        pairs[key]['emotion'] = emo_label
        pairs[key]['time'] = parts[1] # é¡¯ç¤ºæ™‚é–“

    # è™•ç†é¤ç›¤ç…§ç‰‡
    for _, row in df_plate.iterrows():
        path = row['local_path']
        filename = os.path.basename(path)
        parts = filename.split('_')
        key = f"{parts[0]}_{parts[1]}"
        
        if key not in pairs: pairs[key] = {}
        pairs[key]['plate'] = path

    # 3. æ¸²æŸ“ UI (ç”±æ–°åˆ°èˆŠæ’åº)
    sorted_keys = sorted(pairs.keys(), reverse=True)
    
    for key in sorted_keys:
        item = pairs[key]
        face_path = item.get('face')
        plate_path = item.get('plate')
        emotion_label = item.get('emotion', 'Unknown')
        time_label = item.get('time', '')

        # å¡ç‰‡å¼ä½ˆå±€
        with st.container(border=True):
            # æ¨™é¡Œåˆ—ï¼šé¡¯ç¤ºæƒ…ç·’èˆ‡æ™‚é–“
            st.markdown(f"#### ğŸ”¥ {emotion_label} <span style='font-size:0.8em; color:gray'>({time_label})</span>", unsafe_allow_html=True)
            
            c1, c2 = st.columns(2)
            
            # å·¦é‚Šï¼šè¡¨æƒ…
            with c1:
                st.caption("ğŸ‘¤ é¡§å®¢è¡¨æƒ…")
                if face_path and os.path.exists(face_path):
                    st.image(face_path, use_container_width=True)
                else:
                    st.warning("å½±åƒéºå¤±")
            
            # å³é‚Šï¼šé¤ç›¤
            with c2:
                st.caption("ğŸ½ï¸ ç•¶ä¸‹é¤ç›¤")
                if plate_path and os.path.exists(plate_path):
                    st.image(plate_path, use_container_width=True)
                else:
                    st.warning("å½±åƒéºå¤±")
def _render_food_insights(db_manager, session_id):
    """
    [NEW] é¤é»æ´å¯Ÿæ¨¡å¼ï¼šä»¥é£Ÿç‰©ç‚ºä¸­å¿ƒï¼Œçµ±è¨ˆé¡§å®¢çš„æƒ…ç·’åæ‡‰
    """
    # 1. æ’ˆå–è©² Session æ‰€æœ‰ã€Œå¼·çƒˆæƒ…ç·’çš„é¤ç›¤ç…§ã€
    # é€™äº›ç…§ç‰‡å·²ç¶“ç¶“é LLM è¾¨è­˜ï¼Œå¸¶æœ‰ food_label
    df_plate = db_manager.get_event_evidence(session_id, "strong_emotion_plate")
    
    if df_plate.empty:
        st.info("å°šç„¡ AI è¾¨è­˜çš„é¤é»æ•¸æ“š")
        return

    # 2. è³‡æ–™å‰è™•ç†ï¼šè§£ææª”åä¸­çš„æƒ…ç·’ï¼Œä¸¦éæ¿¾ç„¡æ•ˆæ•¸æ“š
    data_list = []
    
    for _, row in df_plate.iterrows():
        # å¦‚æœä½¿ç”¨è€…å·²ç¶“æ‰‹å‹•å–æ¶ˆå‹¾é¸ (human_corrected=0)ï¼Œå°±æ’é™¤é€™ç­†è³‡æ–™
        if row['human_corrected'] == 0:
            continue
            
        food_name = row['food_label'] if row['food_label'] else "Unknown"
        path = row['local_path']
        evidence_id = row['id']
        
        # å¾æª”åè§£ææƒ…ç·’
        # æ ¼å¼: {æ™‚é–“}_{æƒ…ç·’1-åˆ†}_{æƒ…ç·’2-åˆ†}_Plate.jpg
        # ç¯„ä¾‹: 12æœˆ01æ—¥_..._é–‹å¿ƒ-98_é©šè‰·-02_Plate.jpg
        try:
            filename = os.path.basename(path)
            parts = filename.split('_')
            
            # å–å‡ºç¬¬ä¸€é«˜åˆ†çš„æƒ…ç·’
            e1_tag = parts[2] # "é–‹å¿ƒ-98"
            emotion_label = e1_tag.split('-')[0] # "é–‹å¿ƒ"
            
            # ç‚ºäº†é¡¯ç¤ºæ–¹ä¾¿ï¼Œæˆ‘å€‘ä¹Ÿå˜—è©¦æ‰¾å°æ‡‰çš„è‡‰éƒ¨ç…§ç‰‡
            # åªè¦æŠŠæª”åçµå°¾çš„ Plate.jpg æ”¹æˆ Face.jpg å³å¯
            face_path = path.replace("_Plate.jpg", "_Face.jpg")
            
            data_list.append({
                "id": evidence_id,
                "food": food_name,
                "emotion": emotion_label,
                "plate_path": path,
                "face_path": face_path,
                "timestamp": parts[1]
            })
        except:
            continue

    if not data_list:
        st.warning("æ²’æœ‰æœ‰æ•ˆçš„é¤é»æ•¸æ“š (å¯èƒ½éƒ½è¢«å–æ¶ˆå‹¾é¸äº†)")
        return

    df_analysis = pd.DataFrame(data_list)

   # 3. UI ä½ˆå±€
    all_foods = sorted(df_analysis['food'].unique().tolist())
    
    c1, c2 = st.columns([1, 3])
    with c1:
        st.markdown("### ğŸ” é¸æ“‡é¤é»")
        # â˜…â˜…â˜… [ä¿®æ­£] åŠ ä¸Š key åƒæ•¸ï¼Œç¶å®š session_id â˜…â˜…â˜…
        selected_food = st.selectbox(
            "è«‹é¸æ“‡è¦åˆ†æçš„èœè‰²", 
            all_foods, 
            key=f"food_select_{session_id}" 
        )
    
    # ç¯©é¸å‡ºè©²é£Ÿç‰©çš„è³‡æ–™
    df_target = df_analysis[df_analysis['food'] == selected_food]
    
    with c2:
        # ==========================================
        # UI å€å¡Š B: çµ±è¨ˆç›´æ–¹åœ–
        # ==========================================
        if not df_target.empty:
            # çµ±è¨ˆå„ç¨®æƒ…ç·’çš„å‡ºç¾æ¬¡æ•¸
            emo_counts = df_target['emotion'].value_counts().reset_index()
            emo_counts.columns = ['Emotion', 'Count']
            
            fig = px.bar(
                emo_counts, x='Emotion', y='Count',
                title=f"é¡§å®¢å°ã€Œ{selected_food}ã€çš„æƒ…ç·’åæ‡‰åˆ†ä½ˆ",
                color='Emotion',
                text_auto=True,
                color_discrete_sequence=px.colors.qualitative.Pastel
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("æ­¤é¤é»ç„¡æ•¸æ“š")

    st.divider()

    # ==========================================
    # UI å€å¡Š C: è©³ç´°ä½è­‰èˆ‡äººå·¥é©—è­‰
    # ==========================================
    st.markdown(f"### âœ… è³‡æ–™é©—è­‰ ({len(df_target)} ç­†)")
    st.caption("å¦‚æœæ‚¨ç™¼ç¾ AI åˆ¤æ–·éŒ¯èª¤ (ä¾‹å¦‚ï¼šé€™ä¸æ˜¯æ¼¢å ¡ï¼Œæˆ–è¡¨æƒ…åˆ¤æ–·éŒ¯èª¤)ï¼Œè«‹å–æ¶ˆå‹¾é¸ï¼Œä¸Šæ–¹çš„çµ±è¨ˆåœ–è¡¨æœƒè‡ªå‹•æ‰£é™¤è©²ç­†æ•¸æ“šã€‚")

    # ä½¿ç”¨ Grid é¡¯ç¤º
    cols = st.columns(3)
    
    for i, row in df_target.iterrows():
        col = cols[i % 3]
        with col:
            with st.container(border=True):
                # æ¨™é¡Œ
                st.markdown(f"**{row['emotion']}** <span style='color:gray'>({row['timestamp']})</span>", unsafe_allow_html=True)
                
                # å·¦å³ä¸¦æ’é¡¯ç¤ºåœ–
                img_c1, img_c2 = st.columns(2)
                with img_c1:
                    if os.path.exists(row['face_path']):
                        st.image(row['face_path'], use_container_width=True)
                    else: st.text("No Face")
                with img_c2:
                    st.image(row['plate_path'], use_container_width=True)

                # å‹¾é¸æ¡† (äº’å‹•æ ¸å¿ƒ)
                # ç•¶ä½¿ç”¨è€…æ”¹è®Šå‹¾é¸ç‹€æ…‹æ™‚ï¼Œæœƒå‘¼å« db_manager æ›´æ–°è³‡æ–™åº«ï¼Œç„¶å¾Œ Streamlit æœƒè‡ªå‹•é‡è·‘ (Rerun)
                checkbox_key = f"chk_food_{row['id']}"
                
                def on_change_callback(eid=row['id'], k=checkbox_key):
                    # å–å¾—æœ€æ–°ç‹€æ…‹
                    new_val = st.session_state[k]
                    # æ›´æ–°è³‡æ–™åº«
                    db_manager.update_evidence_feedback(eid, new_val)
                    # æç¤º
                    if not new_val:
                        st.toast(f"å·²ç§»é™¤ ID {eid}ï¼Œåœ–è¡¨å°‡é‡æ–°è¨ˆç®—")

                st.checkbox(
                    "è³‡æ–™æ­£ç¢º (ç´å…¥çµ±è¨ˆ)", 
                    value=True, 
                    key=checkbox_key,
                    on_change=on_change_callback
                )

def _render_all_emotions_gallery(db_manager, session_id):
    """
    [NEW] é¡¯ç¤ºæ‰€æœ‰åµæ¸¬åˆ°çš„æƒ…ç·’ç…§ç‰‡ (å« Top 2 åˆ†æ•¸)
    """
    df = db_manager.get_event_evidence(session_id, "strong_emotion_face")
    
    if df.empty:
        st.info("å°šç„¡æƒ…ç·’ç´€éŒ„")
        return

    # ä½¿ç”¨ Grid ä½ˆå±€
    cols = st.columns(4)
    
    for i, row in df.iterrows():
        path = row['local_path']
        if not os.path.exists(path): continue
            
        filename = os.path.basename(path)
        # è§£ææª”å: æ™‚é–“_æƒ…ç·’1-åˆ†æ•¸_æƒ…ç·’2-åˆ†æ•¸_Face.jpg
        try:
            parts = filename.split('_')
            # parts[0]: æ—¥æœŸ, parts[1]: æ™‚é–“
            time_str = f"{parts[1]}" 
            
            # è§£ææƒ…ç·’ 1 (ä¾‹å¦‚ "é–‹å¿ƒ-98")
            e1_part = parts[2].split('-')
            e1_label = e1_part[0]
            e1_score = e1_part[1]
            
            # è§£ææƒ…ç·’ 2 (ä¾‹å¦‚ "é©šè‰·-02")
            # èˆŠçš„æª”æ¡ˆå¯èƒ½æ²’æœ‰ç¬¬äºŒæƒ…ç·’ï¼Œè¦åšé˜²å‘†
            if len(parts) >= 5:
                e2_part = parts[3].split('-')
                e2_label = e2_part[0]
                e2_score = e2_part[1]
                caption_text = f"ğŸ¥‡{e1_label}({e1_score}%) | ğŸ¥ˆ{e2_label}({e2_score}%)"
            else:
                caption_text = f"ğŸ¥‡{e1_label}({e1_score}%)"
                
        except:
            # è§£æå¤±æ•— (å¯èƒ½æ˜¯èˆŠæª”æ¡ˆ)
            time_str = "Unknown"
            caption_text = "Legacy Data"

        col = cols[i % 4]
        with col:
            st.image(path, use_container_width=True)
            st.caption(f"ğŸ•’ {time_str}")
            st.markdown(f"**{caption_text}**")

# ==========================================
# [é‡æ§‹] ç¨ç«‹çš„ Tab æ¸²æŸ“å‡½å¼ (Function Components)
# ==========================================




def _render_tab_global(client, db_manager, df_sessions, t):
    """Tab 5: èœè‰²ç ”ç™¼å ±å‘Š (Menu R&D Report)"""
    st.subheader("ğŸ” èœè‰²ç ”ç™¼å ±å‘Š (Menu Insights)")
    st.caption("é‡å°ç‰¹å®šèœè‰²çš„é¡§å®¢æƒ…ç·’åæ‡‰é€²è¡Œåˆ†æï¼Œé©åˆä¸»å»šèˆ‡èœå–®ç ”ç™¼äººå“¡ã€‚")

    if df_sessions.empty:
        st.warning("âš ï¸ ç›®å‰é¸å®šçš„æ™‚é–“ç¯„åœå…§ç„¡ Session è³‡æ–™ï¼Œç„¡æ³•åˆ†æèœè‰²ã€‚")
        return
    
    # --- 1. è³‡æ–™èšåˆ (Aggregation) ---
    # é€™è£¡çš„é‚è¼¯æ˜¯å°‡æ‰€æœ‰å ´æ¬¡çš„ã€Œé¤é»æƒ…ç·’ã€å½™æ•´èµ·ä¾†
    all_food_data = []
    
    for _, session_row in df_sessions.iterrows():
        sid = session_row['session_id_raw']
        # æ’ˆå–è©² Session çš„å¼·çƒˆæƒ…ç·’é¤é»è­‰æ“š
        df_evidence = db_manager.get_event_evidence(sid, "strong_emotion_plate")
        
        if df_evidence.empty: continue
            
        for _, row in df_evidence.iterrows():
            if row['human_corrected'] == 0: continue # æ’é™¤äººå·¥å¦æ±ºçš„
            
            food_name = row['food_label'] if row['food_label'] else "Unknown"
            
            # è§£ææƒ…ç·’ (å¾æª”å: æ—¥æœŸ_æƒ…ç·’-åˆ†æ•¸_...)
            try:
                fname = os.path.basename(row['local_path'])
                parts = fname.split('_')
                # å‡è¨­æª”åçµæ§‹å›ºå®šï¼Œå–ç¬¬3éƒ¨åˆ†çš„æƒ…ç·’æ¨™ç±¤
                # ç¯„ä¾‹: ..._é–‹å¿ƒ-98_...
                emotion_tag = parts[2].split('-')[0] 
                
                all_food_data.append({
                    "food": food_name,
                    "emotion": emotion_tag
                })
            except:
                continue

    if not all_food_data:
        st.info("åœ¨æ­¤æ™‚é–“ç¯„åœå…§ï¼Œå°šæœªè’é›†åˆ°è¶³å¤ çš„èœè‰²æƒ…ç·’æ¨£æœ¬ (éœ€è§¸ç™¼å¼·çƒˆæƒ…ç·’å¿«ç…§)ã€‚")
        return

    # è½‰æ›ç‚º DataFrame æ–¹ä¾¿çµ±è¨ˆ
    df_analysis = pd.DataFrame(all_food_data)

    # æº–å‚™çµ¦ LLM çš„çµ±è¨ˆæ•¸æ“šï¼š {'æ¼¢å ¡': {'é–‹å¿ƒ': 5, 'å«Œæ£„': 1}, ...}
    food_stats = {}
    for food in df_analysis['food'].unique():
        sub_df = df_analysis[df_analysis['food'] == food]
        counts = sub_df['emotion'].value_counts().to_dict()
        food_stats[food] = counts

    if "menu_report_content" not in st.session_state:
        st.session_state.menu_report_content = None

    # --- 2. AI èœè‰²å ±å‘Šå€å¡Š ---
    with st.container(border=True):
        c1, c2 = st.columns([3, 1])
        with c1:
            st.markdown(f"**å·²è’é›†æ¨£æœ¬æ•¸**: `{len(df_analysis)}` ç­†åæ‡‰ | **æ¶µè“‹èœè‰²**: `{len(food_stats)}` é“")
        with c2:
            gen_menu_btn = st.button("âœ¨ ç”Ÿæˆç ”ç™¼å ±å‘Š", type="primary", use_container_width=True)

        if gen_menu_btn:
            if not client:
                st.error("æœªè¨­å®š OpenAI API Key")
            else:
                with st.spinner("AI æ­£åœ¨åˆ†æèœè‰²è¡¨ç¾..."):
                    # å‘¼å«æˆ‘å€‘å‰›æ–°å¢çš„å°ˆç”¨å‡½å¼
                    async def run_menu_gpt():
                        try:
                            resp, _ = await llm.generate_menu_report(food_stats, client)
                            return resp
                        except Exception as e:
                            return f"Error: {e}"

                    # â˜… å­˜å…¥ session_state
                    st.session_state.menu_report_content = asyncio.run(run_menu_gpt())
        
        # [æ–°å¢] é¡¯ç¤ºå ±å‘Šèˆ‡ä¸‹è¼‰æŒ‰éˆ•
        if st.session_state.menu_report_content:
            st.markdown("---")
            st.markdown(st.session_state.menu_report_content)
            
            # è£½ä½œ Word æª”
            docx_file = _create_docx(st.session_state.menu_report_content)
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰èœè‰²å ±å‘Š (.docx)",
                data=docx_file,
                file_name=f"Menu_Report_{datetime.date.today()}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                type="secondary"
            )

    # --- 3. å–®å“é …è©³ç´°åœ–è¡¨ (åŸæœ¬çš„åŠŸèƒ½) ---
    st.divider()
    st.markdown("#### ğŸ” å–®å“é …è©³ç´°æ•¸æ“š")
    
    c1, c2 = st.columns([1, 2])
    with c1:
        food_list = sorted(list(food_stats.keys()))
        selected_food = st.selectbox("é¸æ“‡è¦é‘½ç ”çš„èœè‰²", food_list)
        if selected_food:
            st.json(food_stats[selected_food])

    with c2:
        if selected_food:
            df_target = df_analysis[df_analysis['food'] == selected_food]
            emo_counts = df_target['emotion'].value_counts().reset_index()
            emo_counts.columns = ['Emotion', 'Count']
            
            fig = px.bar(
                emo_counts, x='Emotion', y='Count',
                title=f"ã€Œ{selected_food}ã€æƒ…ç·’åˆ†ä½ˆåœ–",
                color='Emotion', text_auto=True,
                color_discrete_sequence=px.colors.qualitative.Pastel
            )
            st.plotly_chart(fig, use_container_width=True)


def _render_tab_overview(client, df_logs, num_groups, groups_df, df_sessions, stats, date_range_strs, t):
    """
    [NEW] ç‡Ÿé‹æ•¸æ“šæ¦‚è§€ Tab
    æ•´åˆäº†ï¼šé—œéµæŒ‡æ¨™ (KPIs)ã€åœ–è¡¨ (äººæµ & æƒ…ç·’)ã€ä»¥åŠç‡Ÿé‹å ±å‘Šç”ŸæˆæŒ‰éˆ•ã€‚
    """
    # --- 1. é ‚éƒ¨é—œéµæ•¸æ“š (Key Metrics) ---
    st.subheader("é—œéµç‡Ÿé‹æŒ‡æ¨™ (Key Performance Indicators)")
    
    # ç¬¬ä¸€æ’ï¼šäººæµç›¸é—œ
    c1, c2, c3 = st.columns(3)
    avg_ppl = 0
    if not df_logs.empty:
        valid_ppl = df_logs[df_logs['people_count'] > 0]['people_count']
        if not valid_ppl.empty:
            avg_ppl = valid_ppl.mean()

    c1.metric(t("metric_groups"), f"{num_groups}")      # ç¸½å®¢çµ„æ•¸
    c2.metric(t("metric_avg_size"), f"{avg_ppl:.1f}")   # å¹³å‡å–®çµ„äººæ•¸
    c3.metric(t("metric_sessions"), len(df_sessions))   # åˆ†æå ´æ¬¡
    
    st.write("") # å¢åŠ ä¸€é»å‚ç›´é–“è·
    
    # ç¬¬äºŒæ’ï¼šæ»¿æ„åº¦èˆ‡å‰©é£Ÿ (å¾åŸæœ¬çš„ Tab 2 & 3 ç§»éä¾†)
    k1, k2, k3 = st.columns(3)
    k1.metric(t("metric_nods"), int(stats['total_nods']))
    k2.metric(t("metric_shakes"), int(stats['total_shakes']))
    k3.metric(t("metric_waste"), f"{stats['waste_rate']:.1f}%")

    st.divider()

    # --- 2. åœ–è¡¨è¦–è¦ºåŒ–å€ (Charts) ---
    chart_c1, chart_c2 = st.columns(2)
    
    # å·¦å´ï¼šäººæµè¶¨å‹¢åœ–
    with chart_c1:
        st.markdown(f"#### {t('chart_traffic')}")
        with st.container(border=True):
            if not df_logs.empty:
                df_chart = df_logs.copy()
                df_chart['timestamp'] = pd.to_datetime(df_chart['timestamp'])
                df_chart = df_chart.set_index('timestamp')
                flow_data = df_chart['people_count'].resample('5T').max().fillna(0)
                st.area_chart(flow_data, color="#06b6d4", use_container_width=True)
            else:
                st.info("NO TRAFFIC DATA")
        
        # å¦‚æœæœ‰è©³ç´°çµ„åˆ¥æ•¸æ“šï¼Œé¡¯ç¤ºåœ¨æ‘ºç–Šé¸å–®ä¸­
        if num_groups > 0:
            with st.expander("æŸ¥çœ‹äººæµè©³ç´°æ•¸æ“š (Groups Detail)"):
                st.dataframe(groups_df, use_container_width=True, hide_index=True)
        
    # å³å´ï¼šæƒ…ç·’åˆ†ä½ˆåœ– (å¾åŸæœ¬çš„æ»¿æ„åº¦åˆ†æç§»éä¾†)
    with chart_c2:
        st.markdown("#### ğŸ˜Š æƒ…ç·’åˆ†ä½ˆ (Emotion Distribution)")
        
        # ç¯©é¸æƒ…ç·’æ•¸æ“š
        df_emotions = df_logs[df_logs['source_type'].isin(['live_session_summary', 'uploaded_video', 'live_dual_cam'])]

        with st.container(border=True):
            if not df_emotions.empty:
                all_emotions = Counter()
                data_found = False

                for _, row in df_emotions.iterrows():
                    e_raw = row.get('emotions')
                    if pd.isna(e_raw) or e_raw == "": continue
                    try:
                        # è™•ç†å­—ä¸²è½‰å­—å…¸
                        e_dict = ast.literal_eval(str(e_raw)) if isinstance(e_raw, str) else e_raw
                        if isinstance(e_dict, dict):
                            for k, v in e_dict.items():
                                if k not in ['Meal_Status', 'status']:
                                    try:
                                        val = float(v) 
                                        if val > 0:
                                            all_emotions[k] += val
                                            data_found = True
                                    except: continue
                    except: continue 

                if data_found and all_emotions:
                    e_df = pd.DataFrame(all_emotions.items(), columns=['Emotion', 'Count'])
                    fig = px.bar(
                        e_df, x='Emotion', y='Count', 
                        color_discrete_sequence=['#8b5cf6'], text_auto=True
                    )
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("å°šç„¡è©³ç´°æƒ…ç·’æ•¸æ“š")
            else:
                st.info("NO DATA")

    st.divider()

    # --- 3. ç‡Ÿé‹å ±å‘Šç”Ÿæˆå€ (Report Generator) ---
    # æŠŠåŸæœ¬ Tab 4 çš„ä¸ŠåŠéƒ¨æŒ‰éˆ•ç§»åˆ°é€™è£¡
    st.subheader("âœ¨ æ™ºæ…§ç‡Ÿé‹é¡§å•")
    # åˆå§‹åŒ– session state ç”¨ä¾†å­˜å ±å‘Š
    if "op_report_content" not in st.session_state:
        st.session_state.op_report_content = None
    
    start_dt_str, end_dt_str = date_range_strs
    
    with st.container(border=True):
        c1, c2 = st.columns([3, 1])
        with c1:
            st.markdown(f"**åˆ†æå€é–“**: `{start_dt_str}` ~ `{end_dt_str}`")
            st.info("é»æ“Šå³å´æŒ‰éˆ•ï¼Œè®“ AI ç‚ºæ‚¨ç¸½çµæœ¬æ™‚æ®µçš„äººæµã€æ»¿æ„åº¦èˆ‡ç‡Ÿé‹ç‹€æ³ï¼Œä¸¦æä¾›è¡Œå‹•å»ºè­°ã€‚")
        
        with c2:
            gen_btn = st.button("ç”Ÿæˆç‡Ÿé‹ç¸½çµå ±å‘Š", type="primary", use_container_width=True)

        if gen_btn:
            # æº–å‚™æ•¸æ“š
            traffic_trend_str = "æ•¸æ“šè™•ç†ä¸­..."
            # (ç°¡åŒ–çš„æµé‡å­—ä¸²è™•ç†é‚è¼¯ï¼Œä¿æŒåŸæ¨£æˆ–ç•¥éç´°ç¯€ä»¥ç¯€çœç¯‡å¹…)
            
            # çœŸå¯¦äººæ•¸è¨ˆç®—
            real_total_customers = int(groups_df['æœ€å¤§äººæ•¸'].sum()) if (not groups_df.empty and 'æœ€å¤§äººæ•¸' in groups_df.columns) else 0
            
            op_stats = {
                "total_customers": real_total_customers,
                "total_sessions": len(df_sessions),
                "satisfaction_index": f"{stats['total_nods']} (Pos) vs {stats['total_shakes']} (Neg)",
                "waste_rate": f"{stats['waste_rate']:.1f}%",
                "traffic_trend": "è©³è¦‹åœ–è¡¨"
            }

            with st.spinner("AI é¡§å•æ­£åœ¨åˆ†æç‡Ÿé‹æ•¸æ“š..."):
                prompt = f"Analyze Operation Stats: {op_stats}"
                async def run_op_rep():
                    try: 
                        # å‘¼å«å¾Œç«¯ LLM
                        BACKEND_CONFIG = {"store_type": "Buffet", "tone": "å°ˆæ¥­å®¢è§€", "tips_style": "ç‡Ÿé‹æµç¨‹å„ªåŒ–"}
                        resp, _ = await llm.summarize_session(op_stats, client=client, custom_instructions=prompt, **BACKEND_CONFIG)
                        return resp
                    except Exception as e:
                        return f"Error: {e}"
                

                st.session_state.op_report_content = asyncio.run(run_op_rep())

        # [æ–°å¢] é¡¯ç¤ºå ±å‘Šèˆ‡ä¸‹è¼‰æŒ‰éˆ• (åªè¦ session_state æœ‰è³‡æ–™å°±é¡¯ç¤º)
        if st.session_state.op_report_content:
            st.markdown("---")
            st.markdown(st.session_state.op_report_content)
            
            # è£½ä½œ Word æª”
            docx_file = _create_docx(st.session_state.op_report_content)
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰ Word å ±å‘Š (.docx)",
                data=docx_file,
                file_name=f"Operational_Report_{datetime.date.today()}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                type="secondary"
            )

# AI Agent
def _render_tab_ai_agent(client, db_manager, df_sessions, df_logs, stats, t):
    """
    [NEW] AI Agent æ™ºæ…§å°è©± Tab (æœ€çµ‚å®Œæ•´ç‰ˆ)
    åŒ…å«ï¼šUX å„ªåŒ–ã€RAG è³‡æ–™æ³¨å…¥ã€Text-to-SQL é›™éšæ®µæ¨ç†ã€è³‡æ–™åº«æ¬„ä½è‡ªå‹•é©é…
    """
    import pandas as pd
    import asyncio
    import os
    import sqlite3
    import re

    # --- 1. CSS ç¾åŒ–æ³¨å…¥ (éœ“è™¹æš—é»‘é¢¨æ ¼) ---
    st.markdown("""
    <style>
        /* èŠå¤©è¦–çª—å®¹å™¨èª¿æ•´ */
        .stChatContainer { padding-right: 10px; }
        
        /* 1. å°è©±å¤–æ¡†å®¹å™¨ç¾åŒ– */
        [data-testid="stVerticalBlockBorderWrapper"] > div {
            border-radius: 15px !important;
            border: 1px solid rgba(255, 255, 255, 0.1) !important;
            background-color: #1e293b !important;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06) !important;
        }

        /* 2. å°è©±æ°£æ³¡ç¾åŒ– */
        .stChatMessage {
            background-color: transparent !important;
            padding: 1rem !important;
            border-radius: 12px !important;
            margin-bottom: 0.5rem !important;
        }

        /* AI (Assistant) - äº®é’è‰²é¢¨æ ¼ */
        .stChatMessage[data-testid="stChatMessage"]:nth-child(odd) {
            background-color: rgba(6, 182, 212, 0.1) !important;
            border-left: 3px solid #06b6d4 !important;
        }

        /* User - æ·¡ç°è‰²é¢¨æ ¼ */
        .stChatMessage[data-testid="stChatMessage"]:nth-child(even) {
            background-color: rgba(255, 255, 255, 0.05) !important;
        }

        /* 3. æ–‡å­—èˆ‡é ­åƒå„ªåŒ– */
        .stChatMessage p {
            font-size: 1.1rem !important;
            line-height: 1.6 !important;
            color: #e2e8f0 !important;
        }
        .stChatMessage .stImage {
            width: 45px !important;
            height: 45px !important;
            border-radius: 50% !important;
            border: 2px solid #334155 !important;
        }
        
        /* 4. æŒ‰éˆ•å„ªåŒ– */
        button[kind="secondary"] {
            border: 1px solid rgba(255,255,255,0.2) !important;
            background-color: transparent !important;
            color: #94a3b8 !important;
        }
        button[kind="secondary"]:hover {
            border-color: #ef4444 !important;
            color: #ef4444 !important;
            background-color: rgba(239, 68, 68, 0.1) !important;
        }
        div.stButton > button {
            border-radius: 20px !important;
            transition: all 0.3s ease;
        }
    </style>
    """, unsafe_allow_html=True)

    # --- 2. åˆå§‹åŒ– Session State ---
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "ğŸ‘‹ å—¨ï¼æˆ‘æ˜¯æ°´æ¯å“¥ï¼Œæ‚¨çš„æ™ºèƒ½å°åŠ©æ‰‹ã€‚æœ‰ä»€éº¼å•é¡Œéƒ½å¯ä»¥å•æˆ‘å‘¦ï¼"}
        ]

    # --- 3. æº–å‚™ Context (AI çš„å¤§è…¦) ---
    
    # (A) è¨ˆç®—ç†±é–€æ™‚æ®µ
    peak_hour = "è³‡æ–™ä¸è¶³"
    if not df_logs.empty:
        try:
            df_logs['hour'] = pd.to_datetime(df_logs['timestamp']).dt.hour
            peak_hour = f"{df_logs['hour'].mode()[0]}é»"
        except: pass

    # (B) æ’ˆå–é£Ÿç‰©æ•¸æ“š
    food_summary_list = []
    if not df_sessions.empty:
        # é™åˆ¶å‰ 50 ç­†ä»¥å„ªåŒ–æ•ˆèƒ½
        for _, row in df_sessions.head(50).iterrows():
            sid = row.get('session_id_raw')
            if not sid: continue
            
            s_time = row['timestamp'].strftime('%H:%M')
            try:
                evidence_df = db_manager.get_event_evidence(sid, "strong_emotion_plate")
                if not evidence_df.empty:
                    for _, e_row in evidence_df.iterrows():
                        if e_row['human_corrected'] == 0: continue
                        f_label = e_row['food_label']
                        if f_label:
                            food_summary_list.append(f"[{s_time}] {f_label}")
            except: pass

    food_context_str = ", ".join(food_summary_list) if food_summary_list else "ç›®å‰å€é–“å…§ç„¡ AI è¾¨è­˜åˆ°çš„é¤é»ç´€éŒ„"
    if len(food_context_str) > 2000: food_context_str = food_context_str[:2000] + "..."

    # (C) Text-to-SQL Schema å®šç¾© (å‘Šè¨´ AI è³‡æ–™åº«é•·æ€æ¨£)
    # ç‰¹åˆ¥èªªæ˜ waste_count æ˜¯æˆ‘å€‘ç¨å¾Œæœƒæ‰‹å‹•è¨ˆç®—ç”Ÿæˆçš„
    db_schema_context = """
    [è³‡æ–™åº«æ¬Šé™]
    ä½ æœ‰æ¬Šé™å­˜å–ä¸€å€‹ SQLite è³‡æ–™åº«ï¼ŒåŒ…å«ä»¥ä¸‹å…©å¼µè¡¨ï¼š
    
    1. è¡¨å: sessions (æ¯ä¸€ç­†ä»£è¡¨ä¸€çµ„å®¢äººçš„ç”¨é¤ç´€éŒ„)
       - Columns: 
         - nod_count (é»é ­æ¬¡æ•¸/int)
         - shake_count (æ–é ­æ¬¡æ•¸/int)
         - waste_count (å‰©é£Ÿæ•¸é‡/int) (è‹¥å¤§æ–¼0ä»£è¡¨æœ‰æµªè²»)
         - timestamp (æ™‚é–“/datetime)
    
    2. è¡¨å: logs (æ¯ä¸€ç­†ä»£è¡¨æ”å½±æ©ŸæŠ“åˆ°çš„äººæµç´€éŒ„)
       - Columns: 
         - people_count (äººæ•¸/int)
         - timestamp (æ™‚é–“/datetime)

    [æŒ‡ä»¤]
    å¦‚æœä½¿ç”¨è€…å•çµ±è¨ˆé¡å•é¡Œ(å¦‚å¹³å‡ã€ç¸½å’Œã€ç‰¹å®šæ™‚æ®µ)ï¼Œè«‹ç”Ÿæˆ SQL æŸ¥è©¢ã€‚
    æ ¼å¼è¦æ±‚ï¼šåªè¼¸å‡º `SQL_QUERY: SELECT ...`ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚
    """

    summary_context = f"""
    [ç‡Ÿé‹æ‘˜è¦]
    - å ´æ¬¡: {len(df_sessions)}
    - æ»¿æ„: {stats['total_nods']} | ä¸æ»¿: {stats['total_shakes']}
    - å‰©é£Ÿæ•¸: {stats['waste_count']}
    - é«˜å³°: {peak_hour}
    [é¤é»ç´€éŒ„] {food_context_str}
    """

    # --- 4. ä»‹é¢ä¸»é«”ï¼šå¡ç‰‡å¼å®¹å™¨ ---
    with st.container(border=True):
        
        # Header
        col_header_L, col_header_R = st.columns([5, 1])
        with col_header_L:
            c_img, c_txt = st.columns([1, 6])
            with c_img:
                img_path = "assets/avatar.png"
                if os.path.exists(img_path): st.image(img_path, width=150)
                else: st.markdown("ğŸ™")
            with c_txt:
                st.markdown("### ğŸ’¬ æ™ºèƒ½å°åŠ©æ‰‹ - æ°´æ¯å“¥")
                st.caption("24å°æ™‚ AI ç‡Ÿé‹é¡§å• | æ”¯æ´ SQL æ•¸æ“šæŸ¥è©¢")
        with col_header_R:
            if st.button("ğŸ—‘ æ¸…ç©º", type="secondary", use_container_width=True):
                st.session_state.messages = [{"role": "assistant", "content": "ç´€éŒ„å·²æ¸…ç©ºï¼"}]
                st.rerun()

        st.divider()

        # å°è©±æ²å‹•å€å¡Š
        chat_container = st.container(height=400)
        with chat_container:
            for msg in st.session_state.messages:
                role = msg["role"]
                # è¨­å®šé ­åƒ
                if role == "user":
                    avatar = "ğŸ‘¤"
                else:
                    avatar = "assets/avatar.png" if os.path.exists("assets/avatar.png") else "ğŸ¤–"
                
                with st.chat_message(role, avatar=avatar):
                    st.markdown(msg["content"])
                    # # å¦‚æœæœ‰ SQL åŸ·è¡Œçµæœï¼Œé¡¯ç¤ºåœ¨æ‘ºç–Šé¸å–®ä¸­
                    # if "sql_query" in msg:
                    #     st.caption(f"ğŸ” SQL: `{msg['sql_query']}`")
                    #     with st.expander("æŸ¥çœ‹åŸå§‹æ•¸æ“š"):
                    #         st.code(msg.get('sql_result', 'No Data'))

    # --- 5. å¿«æ·æŒ‰éˆ•å€ ---
    st.write("ğŸ’¡ **å¿«æ·æå•ï¼š**")
    b1, b2, b3, b4 = st.columns(4)
    user_click_prompt = None

    if b1.button("ğŸ“Š ä»Šæ—¥ç¸½çµ"): user_click_prompt = "è«‹ç¸½çµä»Šå¤©çš„ç‡Ÿé‹ç‹€æ³èˆ‡é—œéµæ•¸æ“šã€‚"
    if b2.button("ğŸ” ç†±é–€é¤é»"): user_click_prompt = "å¤§å®¶éƒ½é»äº†ä»€éº¼ï¼Ÿæœ‰æ²’æœ‰ç‰¹å®šæ™‚æ®µåå¥½ï¼Ÿ"
    if b3.button("ğŸ“ˆ å¹³å‡æ»¿æ„åº¦"): user_click_prompt = "å¹³å‡æ¯çµ„å®¢äººçš„æ»¿æ„é»é ­æ¬¡æ•¸æ˜¯å¤šå°‘ï¼Ÿ"
    if b4.button("ğŸ—‘ï¸ å‰©é£Ÿåˆ†æ"): user_click_prompt = "ç¸½å…±æœ‰å¤šå°‘å ´æ¬¡å‡ºç¾å‰©é£Ÿï¼Ÿæ¯”ä¾‹æ˜¯å¤šå°‘ï¼Ÿ"

    # --- 6. è¼¸å…¥è™•ç†é‚è¼¯ ---
    chat_input_text = st.chat_input("è¼¸å…¥å•é¡Œ...")
    final_prompt = user_click_prompt if user_click_prompt else chat_input_text

    if final_prompt:
        # 1. é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯
        st.session_state.messages.append({"role": "user", "content": final_prompt})
        with chat_container:
            with st.chat_message("user", avatar="ğŸ‘¤"):
                st.markdown(final_prompt)

        # 2. AI è™•ç† (Text-to-SQL Magic)
        if not client:
            st.error("âš ï¸ æœªè¨­å®š OpenAI API Key")
        else:
            with chat_container:
                avatar = "assets/avatar.png" if os.path.exists("assets/avatar.png") else "ğŸ¤–"
                with st.chat_message("assistant", avatar=avatar):
                    status_placeholder = st.empty()
                    
                    with st.spinner("æ°´æ¯å“¥æ­£åœ¨æ€è€ƒ..."):
                        async def run_analysis():
                            # System Prompt åŒ…å« Schema
                            full_prompt = f"""
                            ä½ æ˜¯ä¸€ä½å°ˆæ¥­é¤å»³é¡§å•ã€‚
                            {summary_context}
                            {db_schema_context}
                            è«‹æ ¹æ“šä½¿ç”¨è€…å•é¡Œåˆ¤æ–·ï¼š
                            1. è‹¥æ˜¯é–’èŠæˆ–æ‘˜è¦ï¼Œç›´æ¥å›ç­”ã€‚
                            2. è‹¥éœ€è¨ˆç®—(å¹³å‡/åŠ ç¸½/éæ¿¾)ï¼Œè«‹ç”Ÿæˆ `SQL_QUERY: SELECT ...`ã€‚
                            3.ã€æ³¨æ„ã€‘è«‹ç›´æ¥èªªå‡ºçµè«–æˆ–æ•¸å­—å³å¯ï¼Œå®Œå…¨ä¸è¦æåˆ°ã€ŒSQLã€ã€ã€Œè³‡æ–™åº«ã€æˆ–ã€ŒæŸ¥è©¢èªå¥ã€ç­‰æŠ€è¡“å­—çœ¼ã€‚èªæ°£è¦åƒæ˜¯ä¸€ä½å°ˆæ¥­çš„åº—é•·åœ¨åšåŒ¯å ±ã€‚
                            """
                            
                            # A. ç¬¬ä¸€æ¬¡è«‹æ±‚
                            resp = await client.chat.completions.create(
                                model="gpt-4o",
                                messages=[{"role": "system", "content": full_prompt}] + st.session_state.messages,
                                temperature=0
                            )
                            first_reply = resp.choices[0].message.content
                            
                            # B. æª¢æŸ¥ SQL
                            sql_match = re.search(r"SQL_QUERY:\s*(SELECT.*)", first_reply, re.IGNORECASE | re.DOTALL)
                            
                            if sql_match:
                                sql_query = sql_match.group(1).strip().replace("```sql", "").replace("```", "").strip()
                                status_placeholder.markdown(f"âš¡ï¸ æ°´æ¯å“¥æ­£åœ¨æŸ¥è©¢è³‡æ–™åº«...")
                                
                                # C. å»ºç«‹å…§å­˜è³‡æ–™åº« (è§£æ±º leftover_data å•é¡Œ)
                                try:
                                    conn = sqlite3.connect(':memory:')
                                    
                                    # --- è™•ç† Sessions è¡¨ ---
                                    clean_sessions = df_sessions.copy()
                                    # [é—œéµé‚è¼¯] å°‡ leftover_data (JSONå­—ä¸²) è½‰ç‚º waste_count (Int)
                                    if 'leftover_data' in clean_sessions.columns:
                                        clean_sessions['waste_count'] = clean_sessions['leftover_data'].apply(
                                            lambda x: 1 if x and isinstance(x, str) and len(x) > 4 else 0
                                        )
                                    else:
                                        clean_sessions['waste_count'] = 0
                                    
                                    # è£œé½Šæ¬„ä½
                                    for col in ['nod_count', 'shake_count', 'timestamp']:
                                        if col not in clean_sessions.columns: clean_sessions[col] = 0
                                    
                                    clean_sessions = clean_sessions[['nod_count', 'shake_count', 'waste_count', 'timestamp']].fillna(0)
                                    clean_sessions.to_sql('sessions', conn, index=False)
                                    
                                    # --- è™•ç† Logs è¡¨ ---
                                    clean_logs = df_logs.copy()
                                    clean_logs = clean_logs[['people_count', 'timestamp']].fillna(0)
                                    clean_logs.to_sql('logs', conn, index=False)
                                    
                                    # åŸ·è¡Œ SQL
                                    query_df = pd.read_sql_query(sql_query, conn)
                                    result_str = query_df.to_string()
                                    conn.close()
                                    
                                    # D. ç¬¬äºŒæ¬¡è«‹æ±‚ (è§£é‡‹çµæœ)
                                    final_prompt_sys = f"SQLæŸ¥è©¢: {sql_query}\nçµæœ:\n{result_str}\nè«‹æ ¹æ“šçµæœç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚"
                                    resp2 = await client.chat.completions.create(
                                        model="gpt-4o",
                                        messages=[{"role": "system", "content": final_prompt_sys}],
                                        temperature=0.7
                                    )
                                    return resp2.choices[0].message.content, sql_query, result_str
                                    
                                except Exception as e:
                                    return f"æŸ¥è©¢å¤±æ•—: {e}", None, None
                            else:
                                return first_reply, None, None

                        reply_text, executed_sql, sql_result = asyncio.run(run_analysis())
                        
                        status_placeholder.empty()
                        
                        # å„²å­˜èˆ‡é¡¯ç¤º
                        msg_data = {"role": "assistant", "content": reply_text}
                        if executed_sql:
                            msg_data["sql_query"] = executed_sql
                            msg_data["sql_result"] = sql_result
                        
                        st.session_state.messages.append(msg_data)
                        
                        # é¡¯ç¤ºé€™æ¬¡çš„å›ç­” (å› ç‚º rerun æœƒæ¸…æ‰ç•«é¢ï¼Œæ‰€ä»¥å­˜æª”å¾Œç›´æ¥ rerun è®“è¿´åœˆé¡¯ç¤º)
                        # ä½†ç‚ºäº†é¿å…ç¬é–“ç©ºç™½ï¼Œæˆ‘å€‘å¯ä»¥é¸æ“‡é€™è£¡ä¸ renderï¼Œç›´æ¥äº¤çµ¦ rerun
        
        # 3. å¼·åˆ¶é‡æ•´ (ç¢ºä¿æµæš¢)
        st.rerun()

def _render_tab_evidence(db, df_sessions, t):
    """
    [NEW] å½±åƒä½è­‰ Tab
    å°ˆé–€é¡¯ç¤ºæ¯ä¸€å€‹ Session çš„è©³ç´°ç…§ç‰‡ (Nod, Shake, Waste, etc.)
    """
    st.subheader(f"{t('header_evidence')} ({len(df_sessions)})")
    st.caption("ä»¥ä¸‹åˆ—å‡ºç¯©é¸æ™‚æ®µå…§çš„æ‰€æœ‰ç”¨é¤ç´€éŒ„åŠå…¶å½±åƒä½è­‰ã€‚")
    
    if not df_sessions.empty:
        # ç¢ºä¿æœ‰ raw_id
        if 'session_id_raw' not in df_sessions.columns:
            df_sessions['session_id_raw'] = df_sessions['timestamp'].dt.strftime('%Y%m%d%H%M%S')

        # é¡¯ç¤ºåˆ—è¡¨ (Expander List)
        for _, row in df_sessions.iterrows():
            ts = row['timestamp']
            time_str = ts.strftime('%m/%d %H:%M')
            unique_session_id = row['session_id_raw']
            
            nods = int(row.get('nod_count', 0))
            shakes = int(row.get('shake_count', 0))
            
            # æ¨™é¡Œé¡¯ç¤ºæ™‚é–“èˆ‡ç°¡æ˜“æƒ…ç·’çµ±è¨ˆ
            label = f"ğŸ“ {time_str} | ğŸ˜Š {nods} vs ğŸ˜Ÿ {shakes}"

            with st.expander(label, expanded=False):
                # é€™è£¡ä¿ç•™åŸæœ¬çš„è©³ç´° Tabs
                t1, t2, t3, t4, t5 = st.tabs(["ğŸ¥ é»é ­ (Nod)", "ğŸ¥ æ–é ­ (Shake)", "ğŸ½ï¸ å‰©é£Ÿ (Waste)", "ğŸ”¥ äº¤å‰æ¯”å°", "ğŸ˜Š æƒ…ç·’å¿«ç…§"])
                
                with t1: _render_evidence_grid(db, unique_session_id, 'nod')
                with t2: _render_evidence_grid(db, unique_session_id, 'shake')
                with t3: _render_evidence_grid(db, unique_session_id, 'plate_vlm')
                with t4: _render_comparison_gallery(db, unique_session_id)
                with t5: _render_all_emotions_gallery(db, unique_session_id)
    else:
        st.info("åœ¨æ­¤å€é–“å…§ç„¡è³‡æ–™ã€‚")

# ==========================================
# ä¸»é¡¯ç¤ºå‡½å¼ (Controller)
# ==========================================

def display(client, db_manager, t=None): 
    if t is None: 
        def t(k): return k
    
    db = db_manager 

    col_title, col_refresh = st.columns([5, 1])
    with col_title:
        st.subheader(t("dash_title"))
    with col_refresh:
        if st.button(t("btn_refresh"), use_container_width=True):
            st.rerun()

    # 1. ç¯©é¸å™¨ (Filter Section)
    with st.container(border=True):
        st.markdown(f"<h5 style='color:var(--primary-color); font-weight:bold;'>{t('filter_title')}</h5>", unsafe_allow_html=True)
        col1, col2, col3 = st.columns(3)
        with col1:
            today = datetime.date.today()
            date_range = st.date_input(t("date_range"), value=[today, today], format="YYYY/MM/DD")
        with col2:
            time_range_option = st.selectbox(t("time_period"), [t("opt_all_day"), t("opt_custom")])
        with col3:
            source_option = st.selectbox(t("data_source"), ["All", "Live", "Video"])

        if len(date_range) != 2:
            st.warning("Please select end date.")
            st.stop()

        start_date, end_date = date_range
        if "All Day" in time_range_option or "å…¨æ—¥" in time_range_option:
            start_dt_str = f"{start_date} 00:00:00"
            end_dt_str = f"{end_date} 23:59:59"
        else:
            col_start, col_end = st.columns(2)
            with col_start:
                s_time = st.time_input("Start", datetime.time(9, 0))
            with col_end:
                e_time = st.time_input("End", datetime.time(21, 0))
            start_dt_str = f"{start_date} {s_time.strftime('%H:%M:%S')}"
            end_dt_str = f"{end_date} {e_time.strftime('%H:%M:%S')}"
            
    # 2. æ•¸æ“šç²å– (Data Fetching)
    if source_option == "Live":
        selected_sources = ['live_stream', 'live_session_summary', 'live_dual_cam']
    elif source_option == "Video":
        selected_sources = ['uploaded_video']
    else:
        selected_sources = ['live_stream', 'live_session_summary', 'uploaded_video', 'live_dual_cam']

    df_logs = db.get_logs_by_range(start_dt_str, end_dt_str, source_types=selected_sources)
    num_groups, groups_df = db.get_customer_groups_analysis(start_dt_str, end_dt_str, gap_minutes=0.6)
    df_sessions_all = db.get_all_session_records()
    
    df_sessions = pd.DataFrame()
    if not df_sessions_all.empty:
        df_sessions_all['timestamp'] = pd.to_datetime(df_sessions_all['timestamp'])
        mask = (df_sessions_all['timestamp'] >= pd.to_datetime(start_dt_str)) & \
               (df_sessions_all['timestamp'] <= pd.to_datetime(end_dt_str))
        df_sessions = df_sessions_all.loc[mask].copy()
        df_sessions = df_sessions.sort_values('timestamp', ascending=False)

    if df_logs.empty and df_sessions.empty and num_groups == 0:
        st.info("NO DATA AVAILABLE.")
        return

    # 3. é å…ˆè¨ˆç®—å…±ç”¨çµ±è¨ˆæ•¸æ“š (Pre-calculate Stats)
    total_nods = df_sessions['nod_count'].sum() if not df_sessions.empty else 0
    total_shakes = df_sessions['shake_count'].sum() if not df_sessions.empty else 0
    waste_count = 0
    if not df_sessions.empty:
        for _, row in df_sessions.iterrows():
            try:
                data = json.loads(row['leftover_data'])
                if data and len(data) > 0: 
                    waste_count += 1
            except: pass
    waste_rate = (waste_count / len(df_sessions) * 100) if not df_sessions.empty else 0
    
    stats = {
        'total_nods': total_nods,
        'total_shakes': total_shakes,
        'waste_count': waste_count,
        'waste_rate': waste_rate
    }

    # 4. ä¸»åˆ†é é¡¯ç¤º (Main Tabs)
    tab1, tab2, tab3, tab4 = st.tabs([
        t("tab_overview"),      # ğŸ“Š ç‡Ÿé‹æ•¸æ“šæ¦‚è§€
        t("tab_menu_insight"),  # ğŸ” èœè‰²æ•´é«”æ´å¯Ÿ
        t("tab_ai_agent"),     # ğŸ¤– AI Agent æ™ºæ…§æ´å¯Ÿ
        t("tab_evidence")      # ğŸ“¸ å€é–“å½±åƒä½è­‰ç´€éŒ„
    ])

    # Tab 1: ç‡Ÿé‹æ•¸æ“šæ¦‚è§€ (åˆä½µäº†äººæµã€æ»¿æ„åº¦ã€åœ–è¡¨ã€å ±å‘ŠæŒ‰éˆ•)
    with tab1:
        _render_tab_overview(
            client, 
            df_logs, 
            num_groups, 
            groups_df, 
            df_sessions, 
            stats, 
            (start_dt_str, end_dt_str), 
            t
        )

    # Tab 3: èœè‰²æ•´é«”æ´å¯Ÿ (åŸæœ¬çš„ Global Insightï¼Œé‚è¼¯ä¸è®Šï¼Œåªæ˜¯æ›ä½ç½®)
    with tab2:
        _render_tab_global(client, db, df_sessions, t)

    # Tab 4: AI Agent (ç›®å‰ç•™ç©º)
    with tab3:
        _render_tab_ai_agent(client, db, df_sessions, df_logs, stats, t)
        # with st.container(border=True):
        #     st.info("ğŸš§ **AI Agent æ™ºæ…§æ´å¯ŸåŠŸèƒ½é–‹ç™¼ä¸­**")
        #     st.markdown("""
        #     æœªä¾†åŠŸèƒ½é å‘Šï¼š
        #     - ğŸ—£ï¸ **è‡ªç„¶èªè¨€å°è©±**ï¼šç›´æ¥å•ç³»çµ±ã€Œä¸Šé€±äº”ä¸­åˆç”Ÿæ„å¥½å—ï¼Ÿã€
        #     - ğŸ¤– **è‡ªå‹•åŒ–ä»»å‹™**ï¼šè¨­å®šæ¢ä»¶è‡ªå‹•ç™¼é€ Line é€šçŸ¥ã€‚
        #     - ğŸ§  **æ·±åº¦é—œè¯åˆ†æ**ï¼šåˆ†æå¤©æ°£ã€ä¿ƒéŠ·æ´»å‹•èˆ‡æƒ…ç·’çš„é—œè¯ã€‚
        #     """)

        # Tab 2: å½±åƒä½è­‰ç´€éŒ„ (ç¨ç«‹å‡ºä¾†çš„ç…§ç‰‡å€)
    with tab4:
        _render_tab_evidence(db, df_sessions, t)