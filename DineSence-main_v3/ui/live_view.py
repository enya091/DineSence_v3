# ui/live_view.py

import streamlit as st
import cv2
import numpy as np
import time
from datetime import datetime
from services import vision_analysis as va
from core import live_analyzer

def display(model_pack, config, db_manager, t=None):
    """
    Live ç›£æ§ä»‹é¢ - æˆ°æƒ…å®¤é¢¨æ ¼ (Command Center Layout)
    """
    # ç‚ºäº†ç›¸å®¹æ€§ï¼Œè‹¥æ²’å‚³å…¥ t (ç¿»è­¯å‡½å¼)ï¼Œçµ¦ä¸€å€‹é è¨­çš„
    if t is None:
        def t(k): return k

    # --- ä¸Šæ–¹æ§åˆ¶åˆ— (HUD) ---
    # ä½¿ç”¨å®¹å™¨åŒ…è£ï¼Œå‰µé€ å„€è¡¨æ¿é ‚éƒ¨çš„æ„Ÿè¦º
    with st.container(border=True):
        c1, c2, c3, c4 = st.columns([1.5, 1, 1, 1])
        with c1:
            st.markdown(f"### ğŸ¥‚ {t('live_status_active')}")
            st.caption(f"SESSION ID: {int(time.time())}")
        
        # é ç•™ä½ç½®çµ¦å³æ™‚æ•¸æ“š (é€™äº›æœƒåœ¨è¿´åœˆä¸­æ›´æ–°)
        with c2:
            metric_people_ph = st.empty()
            metric_people_ph.metric(t("metric_people"), "0", border=True)
        with c3:
            metric_sat_ph = st.empty()
            metric_sat_ph.metric(t("metric_satisfaction"), "0%", border=True)
        with c4:
            metric_event_ph = st.empty()
            metric_event_ph.metric(t("metric_events"), "0", border=True)

    st.write("") # é–“è·

    # --- ä¸»ä½ˆå±€ï¼šå·¦å´å½±åƒ (3) vs å³å´è³‡è¨Šæµ (1.2) ---
    main_col, info_col = st.columns([3, 1.2])

    with main_col:
        # å½±åƒé¡¯ç¤ºå€å¡Š
        with st.container(border=True):
            video_placeholder = st.empty()
            # é è¨­é¡¯ç¤ºä¸€å¼µå¾…æ©Ÿåœ–æˆ–é»‘åº•
            video_placeholder.markdown(
                f"""
                <div style='background-color:#000; height:450px; display:flex; 
                align-items:center; justify-content:center; color:#c18440; border-radius:8px;'>
                    <h3>{t("waiting")}</h3>
                </div>
                """, 
                unsafe_allow_html=True
            )

    with info_col:
        # å³å´æ§åˆ¶èˆ‡æ—¥èªŒå€
        with st.container(border=True):
            st.markdown(f"#### âš™ï¸ {t('settings')}")
            camera_source = st.radio(
                t("cam_input"), 
                options=[0, 1, "RTSP"], 
                horizontal=True,
                label_visibility="collapsed"
            )
            
            col_btn1, col_btn2 = st.columns(2)
            with col_btn1:
                start_btn = st.button(t("start_btn"), type="primary", use_container_width=True)
            with col_btn2:
                stop_btn = st.button(t("stop_btn"), type="secondary", use_container_width=True)

        st.write("")
        
        # å³æ™‚æ—¥èªŒ (æ¨¡æ“¬çµ‚ç«¯æ©Ÿæ•ˆæœ)
        with st.container(border=True):
            st.markdown(f"#### {t('log_title')}")
            log_placeholder = st.empty()
            log_placeholder.code("System Ready...\nWaiting for input...", language="bash")
            
        # AI æ´å¯Ÿå€
        with st.container(border=True):
            st.markdown(f"#### ğŸ§  {t('ai_insight')}")
            insight_placeholder = st.empty()
            insight_placeholder.info("AI Analysis Module Standby")

    # --- é‚è¼¯è™•ç† (ç¶­æŒåŸæœ¬é‚è¼¯ï¼Œå°æ¥ UI Placeholder) ---
    if start_btn:
        st.session_state['is_running'] = True
    if stop_btn:
        st.session_state['is_running'] = False

    if st.session_state.get('is_running'):
        cap = cv2.VideoCapture(camera_source)
        
        # ç”¨æ–¼ç´¯ç© Log çš„åˆ—è¡¨
        log_buffer = []
        MAX_LOG_LINES = 8
        event_count = 0

        while cap.isOpened() and st.session_state['is_running']:
            ret, frame = cap.read()
            if not ret:
                st.error("Cannot read camera feed.")
                break

            # 1. åˆ†æç•«é¢ (èª¿ç”¨ core é‚è¼¯)
            processed_frame, frame_data = live_analyzer.process_frame(
                frame, 
                model_pack, 
                st.session_state['db_manager']
            )
            
            # 2. æ›´æ–°ç•«é¢ (å·¦å´å¤§åœ–)
            # å°‡ BGR è½‰ RGB ä»¥ä¾› Streamlit é¡¯ç¤º
            frame_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
            video_placeholder.image(frame_rgb, use_container_width=True, channels="RGB")

            # 3. æ›´æ–° HUD æ•¸æ“š (ä¸Šæ–¹)
            ppl_count = frame_data.get('people_count', 0)
            metric_people_ph.metric(t("metric_people"), f"{ppl_count}")
            
            # æ¨¡æ“¬æ»¿æ„åº¦è¨ˆç®— (é€™è£¡å¯ç”¨ frame_data è£¡çš„çœŸå¯¦æ•¸æ“š)
            nods = frame_data.get('nod_detected', False)
            shakes = frame_data.get('shake_detected', False)
            
            if nods or shakes:
                event_count += 1
                metric_event_ph.metric(t("metric_events"), f"{event_count}")
                
                # æ›´æ–°æ—¥èªŒ
                timestamp = datetime.now().strftime("%H:%M:%S")
                event_type = "NOD (Positive)" if nods else "SHAKE (Negative)"
                log_msg = f"[{timestamp}] DETECTED: {event_type}"
                log_buffer.append(log_msg)
                if len(log_buffer) > MAX_LOG_LINES:
                    log_buffer.pop(0)
                
                # åˆ·æ–° Log é¡¯ç¤º
                log_text = "\n".join(log_buffer)
                log_placeholder.code(log_text if log_text else "Monitoring...", language="bash")

            # 4. æ›´æ–° AI æ´å¯Ÿ (å¦‚æœæœ‰)
            if 'ai_insight' in frame_data and frame_data['ai_insight']:
                 insight_placeholder.success(frame_data['ai_insight'])

            time.sleep(0.03) # æ§åˆ¶ FPS

        cap.release()
        st.info("System Stopped.")